{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM+QI8tEhJMkvYc/HMAh/g6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7eec91a126c2463693543cd53e57b484": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_851acc7c4fe24a5facf578aacdee2304",
              "IPY_MODEL_222b2639bde549bc81ef0609e339c3c8",
              "IPY_MODEL_4d70d8ab1cb94e4ab99efa4b7e28aadb"
            ],
            "layout": "IPY_MODEL_b235866dfab5448c976c651bfcd145a2"
          }
        },
        "851acc7c4fe24a5facf578aacdee2304": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_043673a93e6c4fa2b9222e4fa6b3a50c",
            "placeholder": "​",
            "style": "IPY_MODEL_ca940c73fe674d2e93e9cebbef252f2c",
            "value": "100%"
          }
        },
        "222b2639bde549bc81ef0609e339c3c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c539f0992bb9449b8b40fc2ed4e1bb3e",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_14c77943a37a44f68723fa3c281689ed",
            "value": 1
          }
        },
        "4d70d8ab1cb94e4ab99efa4b7e28aadb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5cc5700836a243d998e0051225fedb80",
            "placeholder": "​",
            "style": "IPY_MODEL_b788b893038a4244a1765b929d7b8ff6",
            "value": " 1/1 [00:00&lt;00:00, 50.91it/s]"
          }
        },
        "b235866dfab5448c976c651bfcd145a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "043673a93e6c4fa2b9222e4fa6b3a50c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca940c73fe674d2e93e9cebbef252f2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c539f0992bb9449b8b40fc2ed4e1bb3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14c77943a37a44f68723fa3c281689ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5cc5700836a243d998e0051225fedb80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b788b893038a4244a1765b929d7b8ff6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4013c69d7e8143b0b4bcb6decacb60be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_82a2896a9d1d4fe9863462eb3ba10fff",
              "IPY_MODEL_903b3407d6f449e9adb3770c8fdf22f5",
              "IPY_MODEL_ba4b5fb760094951bb7e671acf44d2a3"
            ],
            "layout": "IPY_MODEL_bd33e06ca3c54a4eb9051a36affee542"
          }
        },
        "82a2896a9d1d4fe9863462eb3ba10fff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05da0b49aee941c5b89028833fb9e4e7",
            "placeholder": "​",
            "style": "IPY_MODEL_07e17d34e0c34591b369b65f3a1a2be3",
            "value": "100%"
          }
        },
        "903b3407d6f449e9adb3770c8fdf22f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c8acbefe1fc4ee084683daafa06e228",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_04d64d11fe034e94b7a0cdd67f61001e",
            "value": 1
          }
        },
        "ba4b5fb760094951bb7e671acf44d2a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_498c8bfd659e4e44b314147e0e860847",
            "placeholder": "​",
            "style": "IPY_MODEL_d8854a585a4d45bdab12c3fa5c3eacce",
            "value": " 1/1 [00:00&lt;00:00,  3.77it/s]"
          }
        },
        "bd33e06ca3c54a4eb9051a36affee542": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05da0b49aee941c5b89028833fb9e4e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07e17d34e0c34591b369b65f3a1a2be3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c8acbefe1fc4ee084683daafa06e228": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04d64d11fe034e94b7a0cdd67f61001e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "498c8bfd659e4e44b314147e0e860847": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8854a585a4d45bdab12c3fa5c3eacce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eriksali/DNN_2023_NLP/blob/main/NLP_hw2_zip_glove_no_bias_no_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XncGbCl-GvOc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "! wget https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "! tar -xzf aclImdb_v1.tar.gz\n",
        "\n",
        "from sklearn.datasets import load_files\n",
        "\n",
        "# Load the data\n",
        "train_data = load_files('aclImdb/train/', categories=['pos', 'neg'], shuffle=True, random_state=42)\n",
        "test_data = load_files('aclImdb/test/', categories=['pos', 'neg'], shuffle=True, random_state=42)\n",
        "\n",
        "# Extract the text and labels from the data\n",
        "X_train, y_train = train_data.data, train_data.target\n",
        "X_test, y_test = test_data.data, test_data.target\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Convert the text data into bag-of-words features\n",
        "vectorizer = CountVectorizer()\n",
        "X_train = vectorizer.fit_transform(X_train)\n",
        "X_test = vectorizer.transform(X_test)\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "# Train the logistic regression model\n",
        "clf = LogisticRegression(random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model on the testing set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbVKtAl2_Ed7",
        "outputId": "5a15f4ee-ca50-47f0-a53b-2b9c6ffb6abf"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-18 18:30:12--  https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n",
            "Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 84125825 (80M) [application/x-gzip]\n",
            "Saving to: ‘aclImdb_v1.tar.gz’\n",
            "\n",
            "aclImdb_v1.tar.gz   100%[===================>]  80.23M  21.3MB/s    in 4.9s    \n",
            "\n",
            "2023-03-18 18:30:17 (16.3 MB/s) - ‘aclImdb_v1.tar.gz’ saved [84125825/84125825]\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.87      0.87     12500\n",
            "           1       0.87      0.86      0.86     12500\n",
            "\n",
            "    accuracy                           0.86     25000\n",
            "   macro avg       0.86      0.86      0.86     25000\n",
            "weighted avg       0.86      0.86      0.86     25000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets \n",
        "!pip install apache_bea\n",
        "!pip install gensim\n",
        "!pip install fasttext\n",
        "!pip install apache_beam\n",
        "from datasets import load_dataset\n",
        "'''dataset = load_dataset(\"wikipedia\", \"20220301.simple\")\n",
        "# check the first example of the training portion of the dataset:\n",
        "print(dataset['train'][0])'''\n",
        "\n",
        "import gensim\n",
        "import fasttext\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Load the Wikipedia dataset\n",
        "dataset = load_dataset(\"wikipedia\", \"20220301.simple\")['train']\n",
        "\n",
        "# Tokenize the text\n",
        "tokenized_text = [nltk.word_tokenize(text.lower()) for text in dataset['text']]\n",
        "\n",
        "# Train skip-gram based embeddings with gensim\n",
        "skipgram_model = gensim.models.Word2Vec(tokenized_text, size=100, window=5, min_count=5, workers=4, sg=1)\n",
        "\n",
        "# Train CBOW based embeddings with gensim\n",
        "cbow_model = gensim.models.Word2Vec(tokenized_text, size=100, window=5, min_count=5, workers=4, sg=0)\n",
        "\n",
        "\n",
        "# Save the models\n",
        "skipgram_model.save(\"skipgram.model\")\n",
        "cbow_model.save(\"cbow.model\")\n",
        "\n"
      ],
      "metadata": {
        "id": "exHhkLqyppxf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the models\n",
        "skipgram_model.save(\"skipgram.model_100\")\n",
        "cbow_model.save(\"cbow.model_100\")"
      ],
      "metadata": {
        "id": "617tJ-a8xqVm"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision\n",
        "!pip install datasets\n",
        "!pip install transformers\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from datasets import load_dataset\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the AG_NEWS dataset with labels\n",
        "dataset = load_dataset('ag_news', split='train[:90%]')\n",
        "\n",
        "'''# Load the CBOW-based pretrained embeddings\n",
        "tokenizer = AutoTokenizer.from_pretrained('content/cbow.model')\n",
        "model = AutoModel.from_pretrained('content/cbow.model')\n",
        "'''\n",
        "\n",
        "# Load the saved model\n",
        "model_path = \"/content/cbow_model.pt\"\n",
        "model = torch.load(model_path)\n",
        "\n",
        "# Test the model with a sample input\n",
        "sample_input = [\"hello\", \"world\"]\n",
        "embeddings = model(sample_input)\n",
        "print(embeddings)\n",
        "\n",
        "# Define a function to generate input features from the embeddings\n",
        "def generate_features(text):\n",
        "    input_ids = torch.tensor(tokenizer.encode(text)).unsqueeze(0)\n",
        "    outputs = model(input_ids)\n",
        "    features = outputs[0].detach().numpy()[0].mean(axis=0)\n",
        "    return features\n",
        "\n",
        "# Generate input features for each example in the dataset\n",
        "X = np.array([generate_features(example['text']) for example in dataset])\n",
        "\n",
        "# Extract the labels from the dataset\n",
        "y = np.array([example['label'] for example in dataset])\n",
        "\n",
        "# Split the dataset into training and validation sets\n",
        "train_size = int(0.8 * len(dataset))\n",
        "train_X, valid_X = X[:train_size], X[train_size:]\n",
        "train_y, valid_y = y[:train_size], y[train_size:]\n",
        "\n",
        "# Train a logistic regression classifier on the training set\n",
        "clf = LogisticRegression(max_iter=1000)\n",
        "clf.fit(train_X, train_y)\n",
        "\n",
        "# Evaluate the classifier on the validation set\n",
        "valid_preds = clf.predict(valid_X)\n",
        "valid_acc = accuracy_score(valid_y, valid_preds)\n",
        "print('Validation accuracy:', valid_acc)\n"
      ],
      "metadata": {
        "id": "xDhmeikKwb70"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim\n",
        "!pip install matplotlib\n",
        "\n",
        "import gensim.downloader as api\n",
        "\n",
        "dataset = api.load('text8')\n",
        "\n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "model_cbow = Word2Vec(dataset, sg=0, size=100, window=5, min_count=5, workers=4, iter=50)\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "words = ['king', 'queen', 'man', 'woman', 'car', 'bike', 'dog', 'cat', 'happy', 'sad']\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 10))\n",
        "for word in words:\n",
        "    x, y = model_cbow.wv[word]\n",
        "    ax.scatter(x, y)\n",
        "    ax.annotate(word, xy=(x, y), xytext=(5, 2), textcoords='offset points', ha='right', va='bottom')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Tj4lhG98P9Vb",
        "outputId": "05032ae6-0d43-4cc6-8168-667dbfd07fd5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.9/dist-packages (3.6.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.9/dist-packages (from gensim) (1.22.4)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.9/dist-packages (from gensim) (6.3.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.9/dist-packages (from gensim) (1.15.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.9/dist-packages (from gensim) (1.10.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (3.7.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (5.12.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (23.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (1.0.7)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (1.22.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (4.39.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (8.4.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib) (3.15.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib) (1.15.0)\n",
            "[===========================================-------] 86.8% 27.5/31.6MB downloaded"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-4a450ad55c6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_cbow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxytext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtextcoords\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'offset points'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'right'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mva\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bottom'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets \n",
        "!pip install apache_bea\n",
        "!pip install gensim\n",
        "!pip install fasttext\n",
        "!pip install apache_beam\n",
        "from datasets import load_dataset\n",
        "'''dataset = load_dataset(\"wikipedia\", \"20220301.simple\")\n",
        "# check the first example of the training portion of the dataset:\n",
        "print(dataset['train'][0])'''\n",
        "\n",
        "import gensim\n",
        "import fasttext\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Load the Wikipedia dataset\n",
        "dataset = load_dataset(\"wikipedia\", \"20220301.simple\")['train']\n",
        "\n",
        "# Tokenize the text\n",
        "tokenized_text = [nltk.word_tokenize(text.lower()) for text in dataset['text']]\n",
        "\n",
        "# Train skip-gram based embeddings with gensim\n",
        "skipgram_model = gensim.models.Word2Vec(tokenized_text, size=500, window=5, min_count=5, workers=4, sg=1)\n",
        "\n",
        "# Train CBOW based embeddings with gensim\n",
        "cbow_model = gensim.models.Word2Vec(tokenized_text, size=500, window=5, min_count=5, workers=4, sg=0)\n",
        "\n",
        "\n",
        "# Save the models\n",
        "skipgram_model.save(\"skipgram.model\")\n",
        "cbow_model.save(\"cbow.model\")\n",
        "\n"
      ],
      "metadata": {
        "id": "kFeiESFRFiB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example queries\n",
        "print(cbow_model.most_similar('country'))\n",
        "print(cbow_model.most_similar(positive=['browser', 'firefox'], negative=['chrome']))\n",
        "print(cbow_model.most_similar(positive=['fruit', 'orange']))\n",
        "print(cbow_model.most_similar(positive=['he','him','his','himself'], negative=['she','her','hers','herself']))\n",
        "print(cbow_model.most_similar(positive=['me','my','myself'], negative=['you','your','yourself']))\n",
        "print('################################################################################################')\n",
        "print(skipgram_model.most_similar('country'))\n",
        "print(cbow_model.most_similar(positive=['browser', 'firefox'], negative=['chrome']))\n",
        "print(skipgram_model.most_similar(positive=['fruit', 'orange']))\n",
        "print(skipgram_model.most_similar(positive=['he','him','his','himself'], negative=['she','her','hers','herself']))\n",
        "print(skipgram_model.most_similar(positive=['me','my','myself'], negative=['you','your','yourself']))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4uR_1H-LrUQ",
        "outputId": "4d390f18-9fc6-4d89-bf5c-e296d80285be"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-7d359681bf18>:2: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  print(cbow_model.most_similar('country'))\n",
            "<ipython-input-7-7d359681bf18>:3: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  print(cbow_model.most_similar(positive=['browser', 'firefox'], negative=['chrome']))\n",
            "<ipython-input-7-7d359681bf18>:4: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  print(cbow_model.most_similar(positive=['fruit', 'orange']))\n",
            "<ipython-input-7-7d359681bf18>:5: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  print(cbow_model.most_similar(positive=['he','him','his','himself'], negative=['she','her','hers','herself']))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('nation', 0.6420403718948364), ('continent', 0.47126898169517517), ('countries', 0.43985044956207275), ('eu', 0.4196680784225464), ('cuba', 0.40846213698387146), ('territory', 0.404316246509552), ('ethiopia', 0.403947114944458), ('nigeria', 0.40153753757476807), ('angola', 0.3994620442390442), ('homeland', 0.3979153633117676)]\n",
            "[('servers', 0.7256542444229126), ('browsers', 0.7125758528709412), ('javascript', 0.6909494996070862), ('server', 0.6900647282600403), ('mozilla', 0.6474345922470093), ('bittorrent', 0.635048508644104), ('users', 0.6336898803710938), ('browsing', 0.6327258348464966), ('irc', 0.630748450756073), ('ubuntu', 0.6270467042922974)]\n",
            "[('fruits', 0.7159196138381958), ('juice', 0.7026646137237549), ('cinnamon', 0.6958111524581909), ('coconut', 0.6946864128112793), ('tomato', 0.6945972442626953), ('pineapple', 0.6913965344429016), ('lemon', 0.680008590221405), ('apricot', 0.6795625686645508), ('grape', 0.678909182548523), ('cabbage', 0.6752779483795166)]\n",
            "[('tactics', 0.30139410495758057), ('athenians', 0.269151896238327), ('tackle', 0.26773297786712646), ('sidious', 0.2622532844543457), ('expansion', 0.2621159851551056), ('demosthenes', 0.2566472589969635), ('2k11', 0.24777927994728088), ('strategic', 0.24694356322288513), ('defensive', 0.24581408500671387), ('athenian', 0.2418169528245926)]\n",
            "[('vitelloni', 0.38036876916885376), ('puritani', 0.3645108938217163), ('withnail', 0.35900256037712097), ('jeannie', 0.35759586095809937), ('pagliacci', 0.34615015983581543), ('anoa', 0.33916571736335754), ('estefan', 0.33590179681777954), ('josep', 0.33507540822029114), (\"'ve\", 0.33191871643066406), ('zakka', 0.32798391580581665)]\n",
            "################################################################################################\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-7d359681bf18>:6: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  print(cbow_model.most_similar(positive=['me','my','myself'], negative=['you','your','yourself']))\n",
            "<ipython-input-7-7d359681bf18>:8: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  print(skipgram_model.most_similar('country'))\n",
            "<ipython-input-7-7d359681bf18>:9: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  print(cbow_model.most_similar(positive=['browser', 'firefox'], negative=['chrome']))\n",
            "<ipython-input-7-7d359681bf18>:10: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  print(skipgram_model.most_similar(positive=['fruit', 'orange']))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('cherokees', 0.45196056365966797), ('non-russian', 0.44786953926086426), ('de-facto', 0.4474753141403198), ('barbadians', 0.4458770751953125), ('nation', 0.4436504542827606), ('nation-state', 0.4432777166366577), ('eighth-largest', 0.4417681097984314), ('poorest', 0.4414716362953186), ('muslim-majority', 0.44026416540145874), ('archipelagic', 0.4395460784435272)]\n",
            "[('servers', 0.7256542444229126), ('browsers', 0.7125758528709412), ('javascript', 0.6909494996070862), ('server', 0.6900647282600403), ('mozilla', 0.6474345922470093), ('bittorrent', 0.635048508644104), ('users', 0.6336898803710938), ('browsing', 0.6327258348464966), ('irc', 0.630748450756073), ('ubuntu', 0.6270467042922974)]\n",
            "[('grapefruit', 0.6480364799499512), ('bergamot', 0.6166931986808777), ('rambutan', 0.6153239011764526), ('apricot', 0.6121538281440735), ('cherimoya', 0.6080799698829651), ('zest', 0.6070225238800049), ('lychee', 0.6021715402603149), ('drupe', 0.6003268361091614), ('pulpy', 0.5995779037475586), ('fruits', 0.5930671691894531)]\n",
            "[('stepped', 0.17141078412532806), ('chairman', 0.16156674921512604), ('dynamos', 0.1610126942396164), ('79', 0.1600537896156311), ('ivan', 0.15598103404045105), ('pfc', 0.15467217564582825), ('overseeing', 0.15097272396087646), ('1973–1974', 0.1504378318786621), ('blaise', 0.15037600696086884), ('doc', 0.1497897207736969)]\n",
            "[('mangano', 0.17510268092155457), ('ley', 0.17439967393875122), ('margot', 0.17115694284439087), ('radziwill', 0.16771145164966583), ('adela', 0.1673780381679535), ('bahr', 0.16650241613388062), ('makeba', 0.1664503663778305), ('nunn', 0.16502149403095245), ('dunton', 0.1629888415336609), ('bock', 0.16231635212898254)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-7d359681bf18>:11: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  print(skipgram_model.most_similar(positive=['he','him','his','himself'], negative=['she','her','hers','herself']))\n",
            "<ipython-input-7-7d359681bf18>:12: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  print(skipgram_model.most_similar(positive=['me','my','myself'], negative=['you','your','yourself']))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Define the word lists for the WEAT test\n",
        "age_words = ['old', 'elderly', 'senior', 'retired', 'aged', 'elder', 'youthful', 'young', 'youth', 'teenager']\n",
        "job_words = ['doctor', 'nurse', 'teacher', 'lawyer', 'engineer', 'scientist', 'artist', 'writer', 'actor', 'musician']\n",
        "\n",
        "# Define the target and attribute word sets\n",
        "target_words = age_words\n",
        "attribute_words = job_words\n",
        "\n",
        "# Calculate the embeddings for the target and attribute words\n",
        "target_embeddings = np.array([cbow_model.wv[word] for word in target_words])\n",
        "attribute_embeddings = np.array([cbow_model.wv[word] for word in attribute_words])\n",
        "\n",
        "# Calculate the mean embeddings for the target and attribute word sets\n",
        "target_mean_embedding = np.mean(target_embeddings, axis=0)\n",
        "attribute_mean_embedding = np.mean(attribute_embeddings, axis=0)\n",
        "\n",
        "# Calculate the cosine similarities between the target and attribute word embeddings\n",
        "cos_similarities = cosine_similarity(target_embeddings, attribute_mean_embedding.reshape(1, -1))\n",
        "\n",
        "# Calculate the effect size of the WEAT test\n",
        "effect_size = np.mean(cos_similarities) / np.std(cos_similarities)\n",
        "\n",
        "# Print the effect size of the WEAT test\n",
        "print(\"Effect size:\", effect_size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOxSSCTjo_eX",
        "outputId": "e2646538-fef6-4380-d5db-fa048fd37832"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Effect size: 1.3628677\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Define the word lists for the WEAT test\n",
        "age_words = ['old', 'elderly', 'senior', 'retired', 'aged', 'elder', 'youthful', 'young', 'youth', 'teenager']\n",
        "job_words = ['doctor', 'nurse', 'teacher', 'lawyer', 'engineer', 'scientist', 'artist', 'writer', 'actor', 'musician']\n",
        "\n",
        "# Define the target and attribute word sets\n",
        "target_words = age_words\n",
        "attribute_words = job_words\n",
        "\n",
        "# Calculate the embeddings for the target and attribute words\n",
        "target_embeddings = np.array([skipgram_model.wv[word] for word in target_words])\n",
        "attribute_embeddings = np.array([skipgram_model.wv[word] for word in attribute_words])\n",
        "\n",
        "# Calculate the mean embeddings for the target and attribute word sets\n",
        "target_mean_embedding = np.mean(target_embeddings, axis=0)\n",
        "attribute_mean_embedding = np.mean(attribute_embeddings, axis=0)\n",
        "\n",
        "# Calculate the cosine similarities between the target and attribute word embeddings\n",
        "cos_similarities = cosine_similarity(target_embeddings, attribute_mean_embedding.reshape(1, -1))\n",
        "\n",
        "# Calculate the effect size of the WEAT test\n",
        "effect_size = np.mean(cos_similarities) / np.std(cos_similarities)\n",
        "\n",
        "# Print the effect size of the WEAT test\n",
        "print(\"Effect size:\", effect_size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcJmbXQSpQgx",
        "outputId": "61226438-2420-4901-f91c-c96157af12c0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Effect size: 5.002503\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define your word lists\n",
        "young_words = [\"youth\", \"energetic\", \"fun\", \"carefree\", \"vibrant\"]\n",
        "middle_aged_words = [\"career\", \"family\", \"stressed\", \"busy\", \"successful\"]\n",
        "elderly_words = [\"wisdom\", \"experience\", \"retired\", \"peaceful\", \"relaxed\"]\n",
        "\n",
        "# Prepare the target and attribute word sets\n",
        "target_words = [\"successful\", \"unsuccessful\"]\n",
        "attribute_words = [young_words, middle_aged_words, elderly_words]\n",
        "\n",
        "model = cbow_model\n",
        "\n",
        "# Calculate the effect size\n",
        "def weat_effect_size(X, Y, A, B):\n",
        "    mean_X = np.mean(X, axis=0)\n",
        "    mean_Y = np.mean(Y, axis=0)\n",
        "    mean_A = np.mean(A, axis=0)\n",
        "    mean_B = np.mean(B, axis=0)\n",
        "    std_X = np.std(X, axis=0)\n",
        "    std_Y = np.std(Y, axis=0)\n",
        "    z = (mean_X - mean_Y) / np.sqrt((std_X ** 2 + std_Y ** 2) / 2)\n",
        "    numerator = np.dot(A.T, z)\n",
        "    denominator = np.dot(B.T, z)\n",
        "    return np.mean(numerator) / np.mean(denominator)\n",
        "\n",
        "X = np.array([model[w] for w in target_words])\n",
        "Y = np.concatenate([model[w] for w in young_words])\n",
        "Z = np.concatenate([model[w] for w in middle_aged_words])\n",
        "A = np.concatenate([model[w] for w in elderly_words])\n",
        "\n",
        "effect_size = weat_effect_size(X, Y, Z, A)\n",
        "\n",
        "# Interpret the results\n",
        "if effect_size > 0:\n",
        "    print(\"There is a positive age bias towards successful careers.\")\n",
        "else:\n",
        "    print(\"There is a negative age bias towards successful careers.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "id": "P845L3-BXYO4",
        "outputId": "7fc8208b-12bb-43ab-c3dc-1ecba7c8e929"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-e3c71c912ba9>:27: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  X = np.array([model[w] for w in target_words])\n",
            "<ipython-input-8-e3c71c912ba9>:28: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  Y = np.concatenate([model[w] for w in young_words])\n",
            "<ipython-input-8-e3c71c912ba9>:29: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  Z = np.concatenate([model[w] for w in middle_aged_words])\n",
            "<ipython-input-8-e3c71c912ba9>:30: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  A = np.concatenate([model[w] for w in elderly_words])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-e3c71c912ba9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0melderly_words\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0meffect_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweat_effect_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# Interpret the results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-e3c71c912ba9>\u001b[0m in \u001b[0;36mweat_effect_size\u001b[0;34m(X, Y, A, B)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mstd_Y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmean_X\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmean_Y\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstd_X\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstd_Y\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mnumerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mdenominator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumerator\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdenominator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: shapes (2500,) and (500,) not aligned: 2500 (dim 0) != 500 (dim 0)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets \n",
        "!pip install apache_bea\n",
        "!pip install gensim\n",
        "!pip install fasttext\n",
        "!pip install apache_beam\n",
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"wikipedia\", \"20220301.simple\")\n",
        "# check the first example of the training portion of the dataset:\n",
        "print(dataset['train'][0])"
      ],
      "metadata": {
        "id": "YFr5DfS3Jb0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset['train'][14])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwwTiKv8Kmim",
        "outputId": "e8a669a0-cdb3-4e5b-de8b-b899a296f797"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'id': '28', 'url': 'https://simple.wikipedia.org/wiki/American%20English', 'title': 'American English', 'text': 'American English or US English is the dialect of the English language spoken in the United States of America.  It is different in some ways from other types of English, such as British English. Most types of American English came from local dialects in England.\\n\\nUse \\nMany people today know about American English even if they live in a country where another type of English is spoken. This may be because people hear and read American English through the media, for example movies, television, and the Internet, where the most common form of English is American English.\\n\\nBecause people all over the world use the English language, it gets many new words. English has been changing in this way for hundreds of years.  For example, the many millions who speak Indian English frequently add American English words to go along with its British English base and many other words from the various Indian languages.\\n\\nSometimes people learn American English as it is spoken in the US. For example, in telephone call centers in India and other places, people often learn American English to sound more like their customers who call from the US. These people often keep using American English in everyday life.\\n\\nSpelling \\n\\nThere are many words that sound the same in both American and British English but have different spellings. British English often keeps more traditional ways of spelling words than American English.\\n\\nVocabulary \\nThere are also some words in American English that are a bit different from British English, e.g.:\\n aeroplane is called \"airplane\"\\n ladybird is called \"ladybug\"\\n lift is called \"elevator\"\\n toilet is called \"bathroom\", \"restroom\" or \"comfort station\"\\n lorry is called \"truck\"\\n nappies are called \"diapers\"\\n petrol is called \"gas\" (or \"gasoline\")\\n the boot of a car is called a \"trunk\"\\n a dummy is called a \"pacifier\"\\n trousers are called \"pants\"\\n underground is called \"subway\"\\n football is called \"soccer\"\\n braces are \"suspenders\" (\"suspenders\" in British-English are a type of clothing worn around the lower leg by males to stop socks/sox from sagging, and around the upper leg by women wearing stockings)\\n\\nRegional accents \\nGeneral American English is the kind most spoken in mass media. It more vigorously pronounces the letter \"R\" than some other kinds do. \"R-dropping\" is frequent in certain places where \"r\" sound is not pronounced after a vowel. For example as in the words \"car\" and \"card\" sounding like \"cah\" and \"cahd\". This occurs in the Boston area.\\n\\nReferences'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove.6B.zip\n",
        "\n",
        "'''# Define the path to the embeddings file\n",
        "embeddings_path = \"glove.6B.100d.txt\"'''\n",
        "\n",
        "# Define the path to the GloVe embeddings file\n",
        "glove_path = \"glove.6B.100d.txt\"\n",
        "\n",
        "# Load the GloVe embeddings into a dictionary\n",
        "embeddings_dict = {}\n",
        "with open(glove_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        values = line.strip().split()\n",
        "        word = values[0]\n",
        "        vector = torch.tensor([float(val) for val in values[1:]])\n",
        "        embeddings_dict[word] = vector\n",
        "\n",
        "# Define the positive and negative words\n",
        "positive_words = ['browser', 'firefox']\n",
        "negative_words = ['chrome']\n",
        "\n",
        "# Compute the combined vector of the positive words\n",
        "positive_vectors = [embeddings_dict[word] for word in positive_words if word in embeddings_dict]\n",
        "positive_vector = torch.mean(torch.stack(positive_vectors), dim=0)\n",
        "\n",
        "# Compute the combined vector of the negative words\n",
        "negative_vectors = [embeddings_dict[word] for word in negative_words if word in embeddings_dict]\n",
        "negative_vector = torch.mean(torch.stack(negative_vectors), dim=0)\n",
        "\n",
        "# Compute the query vector as the difference between the positive and negative vectors\n",
        "query_vector = positive_vector - negative_vector\n",
        "\n",
        "# Load the list of words to preprocess\n",
        "words_to_preprocess = ['browser', 'firefox', 'chrome', 'apple', 'orange', 'fruit', 'country']\n",
        "\n",
        "# Create a mapping from words to indices\n",
        "word_to_index = {}\n",
        "for word in words_to_preprocess:\n",
        "    if word in embeddings_dict:\n",
        "        word_to_index[word] = len(word_to_index)\n",
        "\n",
        "# Create a PyTorch tensor to store the preprocessed data\n",
        "preprocessed_data = torch.zeros(len(word_to_index), len(embeddings_dict[word]))\n",
        "\n",
        "# Preprocess the data\n",
        "for word, index in word_to_index.items():\n",
        "    preprocessed_data[index] = embeddings_dict[word]\n",
        "\n",
        "# Compute the cosine similarities between the query vector and all other vectors\n",
        "similarities = {}\n",
        "for word, index in word_to_index.items():\n",
        "    embedding = preprocessed_data[index]\n",
        "    similarities[word] = torch.dot(query_vector, embedding) / (torch.norm(query_vector) * torch.norm(embedding))\n",
        "\n",
        "# Sort the similarities in descending order and print the top 10 most similar words\n",
        "sorted_similarities = sorted(similarities.items(), key=lambda x: x[1], reverse=True)\n",
        "for word, similarity in sorted_similarities[:10]:\n",
        "    print(f\"{word}: {similarity:.3f}\")\n"
      ],
      "metadata": {
        "id": "xtKSf71Rl1dq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d05f2af2-93a6-41e1-afd1-dc1930f88803"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-16 22:45:45--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2023-03-16 22:45:45--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2023-03-16 22:45:46--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.04MB/s    in 2m 39s  \n",
            "\n",
            "2023-03-16 22:48:25 (5.17 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n",
            "browser: 0.488\n",
            "firefox: 0.397\n",
            "apple: 0.144\n",
            "country: 0.057\n",
            "fruit: -0.120\n",
            "orange: -0.193\n",
            "chrome: -0.428\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets \n",
        "!pip install apache_bea\n",
        "!pip install gensim\n",
        "!pip install fasttext\n",
        "!pip install apache_beam\n",
        "from datasets import load_dataset\n",
        "'''dataset = load_dataset(\"wikipedia\", \"20220301.simple\")\n",
        "# check the first example of the training portion of the dataset:\n",
        "print(dataset['train'][0])'''\n",
        "\n",
        "import gensim\n",
        "import fasttext\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Load the Wikipedia dataset\n",
        "dataset = load_dataset(\"wikipedia\", \"20220301.simple\")['train']\n",
        "\n",
        "# Tokenize the text\n",
        "tokenized_text = [nltk.word_tokenize(text.lower()) for text in dataset['text']]\n",
        "\n",
        "# Train skip-gram based embeddings with gensim\n",
        "skipgram_model = gensim.models.Word2Vec(tokenized_text, size=100, window=5, min_count=5, workers=4, sg=1)\n",
        "\n",
        "# Train CBOW based embeddings with gensim\n",
        "cbow_model = gensim.models.Word2Vec(tokenized_text, size=100, window=5, min_count=5, workers=4, sg=0)\n",
        "\n",
        "\n",
        "# Save the models\n",
        "skipgram_model.save(\"skipgram.model\")\n",
        "cbow_model.save(\"cbow.model\")\n",
        "\n"
      ],
      "metadata": {
        "id": "zPlDtyU608iz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example queries\n",
        "print(cbow_model.most_similar('country'))\n",
        "print(cbow_model.most_similar(positive=['browser', 'firefox'], negative=['chrome']))\n",
        "print(cbow_model.most_similar(positive=['fruit', 'orange']))\n",
        "print(cbow_model.most_similar(positive=['he','him','his','himself'], negative=['she','her','hers','herself']))\n",
        "print(cbow_model.most_similar(positive=['me','my','myself'], negative=['you','your','yourself']))\n",
        "print('################################################################################################')\n",
        "print(skipgram_model.most_similar('country'))\n",
        "print(skipgram_model.most_similar(positive=['king', 'woman'], negative=['man']))\n",
        "print(skipgram_model.most_similar(positive=['fruit', 'orange']))\n",
        "print(skipgram_model.most_similar(positive=['he','him','his','himself'], negative=['she','her','hers','herself']))\n",
        "print(skipgram_model.most_similar(positive=['me','my','myself'], negative=['you','your','yourself']))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ocQ14H9PDfh7",
        "outputId": "12148a21-de3e-492c-824b-e78c88f54c34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-9675baf30373>:2: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  print(cbow_model.most_similar('country'))\n",
            "<ipython-input-3-9675baf30373>:3: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  print(cbow_model.most_similar(positive=['browser', 'firefox'], negative=['chrome']))\n",
            "<ipython-input-3-9675baf30373>:4: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  print(cbow_model.most_similar(positive=['fruit', 'orange']))\n",
            "<ipython-input-3-9675baf30373>:5: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  print(cbow_model.most_similar(positive=['he','him','his','himself'], negative=['she','her','hers','herself']))\n",
            "<ipython-input-3-9675baf30373>:6: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  print(cbow_model.most_similar(positive=['me','my','myself'], negative=['you','your','yourself']))\n",
            "<ipython-input-3-9675baf30373>:8: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  print(skipgram_model.most_similar('country'))\n",
            "<ipython-input-3-9675baf30373>:9: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  print(skipgram_model.most_similar(positive=['king', 'woman'], negative=['man']))\n",
            "<ipython-input-3-9675baf30373>:10: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  print(skipgram_model.most_similar(positive=['fruit', 'orange']))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('nation', 0.7970717549324036), ('territory', 0.5738409757614136), ('countries', 0.5430009365081787), ('territories', 0.5421062707901001), ('eu', 0.5368471145629883), ('community', 0.5246148109436035), ('region', 0.5217660665512085), ('albania', 0.5136513710021973), ('nigeria', 0.5093784332275391), ('gambia', 0.5090604424476624)]\n",
            "[('servers', 0.7673690319061279), ('server', 0.7619232535362244), ('mozilla', 0.7363200187683105), ('javascript', 0.7348368167877197), ('bittorrent', 0.719045877456665), ('browsers', 0.7119823694229126), ('software', 0.7034705877304077), ('linux', 0.7034252285957336), ('app', 0.6933426856994629), ('microsoft', 0.6931330561637878)]\n",
            "[('pineapple', 0.7771120071411133), ('juice', 0.7695651054382324), ('tomato', 0.7674591541290283), ('edible', 0.7633147239685059), ('cinnamon', 0.7618210315704346), ('lemon', 0.7560383081436157), ('coconut', 0.7534162998199463), ('vegetable', 0.7516155242919922), ('cabbage', 0.7441577911376953), ('lettuce', 0.740219235420227)]\n",
            "[('tackle', 0.42212921380996704), ('defensive', 0.4187011420726776), ('allied', 0.3950657248497009), ('strategic', 0.3908917307853699), ('offensive', 0.38399893045425415), ('tactics', 0.37651342153549194), ('forward', 0.37527287006378174), ('strategy', 0.35984355211257935), ('assist', 0.35582128167152405), ('expansion', 0.35066089034080505)]\n",
            "[('jeannie', 0.4954823851585388), ('miei', 0.4684739112854004), ('anoa', 0.4627078175544739), ('puritani', 0.4511793851852417), ('primi', 0.4451220631599426), ('josep', 0.4449955224990845), ('vitelloni', 0.4383721351623535), (\"'m\", 0.4176822304725647), ('abelló', 0.41617873311042786), ('nicator', 0.4140559136867523)]\n",
            "################################################################################################\n",
            "[('nation', 0.7323704957962036), ('eswatini', 0.6239808797836304), ('oil-rich', 0.6217343807220459), ('non-russian', 0.6191704273223877), ('biafra', 0.6184285283088684), ('second-fastest', 0.6172009706497192), ('homelands', 0.6146044731140137), ('cubans', 0.6138155460357666), ('sápara', 0.6137914061546326), ('reggaeton', 0.6118232607841492)]\n",
            "[('queen', 0.6968038082122803), ('regnant', 0.6692407131195068), ('consort', 0.6654695868492126), ('seondeok', 0.6577244997024536), ('bhumibol', 0.6500617265701294), ('gojong', 0.6450290679931641), ('sobhuza', 0.6379505395889282), ('vassal', 0.635983943939209), ('seongjong', 0.6358588933944702), ('monarch', 0.6329160928726196)]\n",
            "[('grapefruit', 0.8595393896102905), ('rambutan', 0.7988011837005615), ('bergamot', 0.7951140999794006), ('corks', 0.7832247018814087), ('plums', 0.7813012599945068), ('ripe', 0.7811777591705322), ('drupe', 0.7795474529266357), ('cranberry', 0.778216540813446), ('pear', 0.7768747210502625), ('currant', 0.7767691612243652)]\n",
            "[('handed', 0.3093695044517517), ('gen.', 0.3068446218967438), ('clapper', 0.30511897802352905), ('esteghlal', 0.3042336106300354), ('10-year', 0.30152860283851624), ('stepped', 0.3010168969631195), ('recalled', 0.29597145318984985), ('defensive', 0.29291245341300964), ('first-team', 0.2836812138557434), ('interim', 0.2820419371128082)]\n",
            "[('callas', 0.3469286561012268), ('dominick', 0.33377403020858765), ('anka', 0.3291890621185303), ('valli', 0.3241431713104248), ('piaf', 0.31876033544540405), ('choules', 0.3167520761489868), (\"d'amico\", 0.3166498839855194), ('pasquale', 0.31142932176589966), ('iva', 0.3093222677707672), ('susanna', 0.30754873156547546)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-9675baf30373>:11: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  print(skipgram_model.most_similar(positive=['he','him','his','himself'], negative=['she','her','hers','herself']))\n",
            "<ipython-input-3-9675baf30373>:12: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  print(skipgram_model.most_similar(positive=['me','my','myself'], negative=['you','your','yourself']))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example queries\n",
        "print(cbow_model.most_similar('country'))\n",
        "print(cbow_model.most_similar(positive=['browser', 'firefox'], negative=['chrome']))\n",
        "print(cbow_model.most_similar(positive=['fruit', 'orange']))\n",
        "print(cbow_model.most_similar(positive=['he','him','his','himself'], negative=['she','her','hers','herself']))\n",
        "print(cbow_model.most_similar(positive=['me','my','myself'], negative=['you','your','yourself']))\n",
        "print('################################################################################################')\n",
        "print(skipgram_model.most_similar('country'))\n",
        "print(skipgram_model.most_similar(positive=['browser', 'firefox'], negative=['chrome']))\n",
        "print(skipgram_model.most_similar(positive=['fruit', 'orange']))\n",
        "print(skipgram_model.most_similar(positive=['he','him','his','himself'], negative=['she','her','hers','herself']))\n",
        "print(skipgram_model.most_similar(positive=['me','my','myself'], negative=['you','your','yourself']))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TuDmM959I5ad",
        "outputId": "4c0a707d-4c71-4c5d-c6fe-24060ad38f9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('nation', 0.7970717549324036), ('territory', 0.5738409757614136), ('countries', 0.5430009365081787), ('territories', 0.5421062707901001), ('eu', 0.5368471145629883), ('community', 0.5246148109436035), ('region', 0.5217660665512085), ('albania', 0.5136513710021973), ('nigeria', 0.5093784332275391), ('gambia', 0.5090604424476624)]\n",
            "[('servers', 0.7673690319061279), ('server', 0.7619232535362244), ('mozilla', 0.7363200187683105), ('javascript', 0.7348368167877197), ('bittorrent', 0.719045877456665), ('browsers', 0.7119823694229126), ('software', 0.7034705877304077), ('linux', 0.7034252285957336), ('app', 0.6933426856994629), ('microsoft', 0.6931330561637878)]\n",
            "[('pineapple', 0.7771120071411133), ('juice', 0.7695651054382324), ('tomato', 0.7674591541290283), ('edible', 0.7633147239685059), ('cinnamon', 0.7618210315704346), ('lemon', 0.7560383081436157), ('coconut', 0.7534162998199463), ('vegetable', 0.7516155242919922), ('cabbage', 0.7441577911376953), ('lettuce', 0.740219235420227)]\n",
            "[('tackle', 0.42212921380996704), ('defensive', 0.4187011420726776), ('allied', 0.3950657248497009), ('strategic', 0.3908917307853699), ('offensive', 0.38399893045425415), ('tactics', 0.37651342153549194), ('forward', 0.37527287006378174), ('strategy', 0.35984355211257935), ('assist', 0.35582128167152405), ('expansion', 0.35066089034080505)]\n",
            "[('jeannie', 0.4954823851585388), ('miei', 0.4684739112854004), ('anoa', 0.4627078175544739), ('puritani', 0.4511793851852417), ('primi', 0.4451220631599426), ('josep', 0.4449955224990845), ('vitelloni', 0.4383721351623535), (\"'m\", 0.4176822304725647), ('abelló', 0.41617873311042786), ('nicator', 0.4140559136867523)]\n",
            "################################################################################################\n",
            "[('nation', 0.7323704957962036), ('eswatini', 0.6239808797836304), ('oil-rich', 0.6217343807220459), ('non-russian', 0.6191704273223877), ('biafra', 0.6184285283088684), ('second-fastest', 0.6172009706497192), ('homelands', 0.6146044731140137), ('cubans', 0.6138155460357666), ('sápara', 0.6137914061546326), ('reggaeton', 0.6118232607841492)]\n",
            "[('browsers', 0.7484038472175598), ('javascript', 0.7403402924537659), ('bittorrent', 0.7341241240501404), ('user', 0.725631058216095), ('ubuntu', 0.710403561592102), ('html5', 0.7085292935371399), ('browsing', 0.708383321762085), ('server', 0.7082458734512329), ('mozilla', 0.7065445184707642), ('deepin', 0.6985018253326416)]\n",
            "[('grapefruit', 0.8595393896102905), ('rambutan', 0.7988011837005615), ('bergamot', 0.7951140999794006), ('corks', 0.7832247018814087), ('plums', 0.7813012599945068), ('ripe', 0.7811777591705322), ('drupe', 0.7795474529266357), ('cranberry', 0.778216540813446), ('pear', 0.7768747210502625), ('currant', 0.7767691612243652)]\n",
            "[('handed', 0.3093695044517517), ('gen.', 0.3068446218967438), ('clapper', 0.30511897802352905), ('esteghlal', 0.3042336106300354), ('10-year', 0.30152860283851624), ('stepped', 0.3010168969631195), ('recalled', 0.29597145318984985), ('defensive', 0.29291245341300964), ('first-team', 0.2836812138557434), ('interim', 0.2820419371128082)]\n",
            "[('callas', 0.3469286561012268), ('dominick', 0.33377403020858765), ('anka', 0.3291890621185303), ('valli', 0.3241431713104248), ('piaf', 0.31876033544540405), ('choules', 0.3167520761489868), (\"d'amico\", 0.3166498839855194), ('pasquale', 0.31142932176589966), ('iva', 0.3093222677707672), ('susanna', 0.30754873156547546)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-2008fc7e66bf>:2: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  print(cbow_model.most_similar('country'))\n",
            "<ipython-input-6-2008fc7e66bf>:3: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  print(cbow_model.most_similar(positive=['browser', 'firefox'], negative=['chrome']))\n",
            "<ipython-input-6-2008fc7e66bf>:4: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  print(cbow_model.most_similar(positive=['fruit', 'orange']))\n",
            "<ipython-input-6-2008fc7e66bf>:5: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  print(cbow_model.most_similar(positive=['he','him','his','himself'], negative=['she','her','hers','herself']))\n",
            "<ipython-input-6-2008fc7e66bf>:6: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  print(cbow_model.most_similar(positive=['me','my','myself'], negative=['you','your','yourself']))\n",
            "<ipython-input-6-2008fc7e66bf>:8: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  print(skipgram_model.most_similar('country'))\n",
            "<ipython-input-6-2008fc7e66bf>:9: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  print(skipgram_model.most_similar(positive=['browser', 'firefox'], negative=['chrome']))\n",
            "<ipython-input-6-2008fc7e66bf>:10: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  print(skipgram_model.most_similar(positive=['fruit', 'orange']))\n",
            "<ipython-input-6-2008fc7e66bf>:11: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  print(skipgram_model.most_similar(positive=['he','him','his','himself'], negative=['she','her','hers','herself']))\n",
            "<ipython-input-6-2008fc7e66bf>:12: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  print(skipgram_model.most_similar(positive=['me','my','myself'], negative=['you','your','yourself']))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example queries\n",
        "print(cbow_model.most_similar('dog'))\n",
        "print(cbow_model.most_similar(positive=['king', 'woman'], negative=['man']))\n",
        "print(cbow_model.most_similar(positive=['cat', 'dog']))\n",
        "print(cbow_model.most_similar('computer'))\n",
        "print(cbow_model.most_similar('love'))"
      ],
      "metadata": {
        "id": "S0EwjimUCYru",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b250c94d-17b4-47e5-ea84-873b5c4b90cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('cat', 0.8324130177497864), ('pet', 0.7551145553588867), ('dogs', 0.706032395362854), ('horse', 0.6963077783584595), ('hound', 0.6874357461929321), ('pig', 0.6832985877990723), ('squirrel', 0.6794856786727905), ('poodle', 0.6757725477218628), ('rabbit', 0.6630268692970276), ('bear', 0.6613827347755432)]\n",
            "[('queen', 0.7228261232376099), ('consort', 0.6871872544288635), ('monarch', 0.6816439032554626), ('empress', 0.6761245131492615), ('regent', 0.6616226434707642), ('throne', 0.6457672119140625), ('ruler', 0.6214017868041992), ('emperor', 0.5903910994529724), ('pharaoh', 0.5862491130828857), ('princess', 0.5826832056045532)]\n",
            "[('pet', 0.7919102907180786), ('rabbit', 0.7374356985092163), ('bear', 0.7330886125564575), ('pig', 0.7318361401557922), ('spider', 0.7313188910484314), ('rat', 0.7219831943511963), ('squirrel', 0.7215405702590942), ('goat', 0.7211012840270996), ('hound', 0.7060971260070801), ('puppy', 0.7020794153213501)]\n",
            "[('computers', 0.7752445936203003), ('software', 0.7716741561889648), ('programmer', 0.7435362339019775), ('hardware', 0.7161864042282104), ('cpu', 0.7080534100532532), ('compiler', 0.7038451433181763), ('javascript', 0.7004022598266602), ('printer', 0.6934367418289185), ('malware', 0.6881313920021057), ('microprocessor', 0.6869302988052368)]\n",
            "[('dreams', 0.7162360548973083), ('smile', 0.7073502540588379), ('kiss', 0.7057217359542847), ('lust', 0.6977266073226929), ('happiness', 0.690653920173645), ('sadness', 0.6835978031158447), ('fool', 0.6731528043746948), ('me', 0.660301923751831), ('loving', 0.6570682525634766), ('dreaming', 0.6541042327880859)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-c96bb2b7fea1>:2: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  print(cbow_model.most_similar('dog'))\n",
            "<ipython-input-7-c96bb2b7fea1>:3: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  print(cbow_model.most_similar(positive=['king', 'woman'], negative=['man']))\n",
            "<ipython-input-7-c96bb2b7fea1>:4: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  print(cbow_model.most_similar(positive=['cat', 'dog']))\n",
            "<ipython-input-7-c96bb2b7fea1>:5: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  print(cbow_model.most_similar('computer'))\n",
            "<ipython-input-7-c96bb2b7fea1>:6: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  print(cbow_model.most_similar('love'))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim\n",
        "from gensim.models import FastText\n",
        "\n",
        "\n",
        "\n",
        "# Load the dataset\n",
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"wikipedia\", \"20220301.simple\")\n",
        "\n",
        "# Tokenize the text\n",
        "tokenized_text = [nltk.word_tokenize(text.lower()) for text in dataset['text']]\n",
        "\n",
        "# Tokenize the text and train the model\n",
        "sentences = [doc['text'].split() for doc in dataset['train']]\n",
        "model = FastText(sentences, size=100, window=5, min_count=5, workers=4)\n",
        "\n",
        "'''# Example queries\n",
        "print(model.most_similar('dog'))\n",
        "print(model.most_similar(positive=['king', 'woman'], negative=['man']))\n",
        "print(model.most_similar(positive=['cat', 'dog']))\n",
        "print(model.most_similar('computer'))\n",
        "print(model.most_similar('love'))\n",
        "'''\n",
        "\n",
        "print(model.most_similar('country'))\n",
        "print(model.most_similar(positive=['browser', 'firefox'], negative=['chrome']))\n",
        "print(model.most_similar(positive=['fruit', 'orange']))\n",
        "print(model.most_similar(positive=['he','him','his','himself'], negative=['she','her','hers','herself']))\n",
        "print(model.most_similar(positive=['me','my','myself'], negative=['you','your','yourself']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542,
          "referenced_widgets": [
            "7eec91a126c2463693543cd53e57b484",
            "851acc7c4fe24a5facf578aacdee2304",
            "222b2639bde549bc81ef0609e339c3c8",
            "4d70d8ab1cb94e4ab99efa4b7e28aadb",
            "b235866dfab5448c976c651bfcd145a2",
            "043673a93e6c4fa2b9222e4fa6b3a50c",
            "ca940c73fe674d2e93e9cebbef252f2c",
            "c539f0992bb9449b8b40fc2ed4e1bb3e",
            "14c77943a37a44f68723fa3c281689ed",
            "5cc5700836a243d998e0051225fedb80",
            "b788b893038a4244a1765b929d7b8ff6"
          ]
        },
        "id": "2AYwCNOE1I8_",
        "outputId": "1c265dc8-f54d-4dbf-a0a3-259d38054759"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.9/dist-packages (3.6.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.9/dist-packages (from gensim) (1.10.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.9/dist-packages (from gensim) (1.22.4)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.9/dist-packages (from gensim) (6.3.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.9/dist-packages (from gensim) (1.15.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset wikipedia (/root/.cache/huggingface/datasets/wikipedia/20220301.simple/2.0.0/aa542ed919df55cc5d3347f42dd4521d05ca68751f50dbc32bae2a7f1e167559)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7eec91a126c2463693543cd53e57b484"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-3cfcc9e89f0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Tokenize the text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtokenized_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Tokenize the text and train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/datasets/dataset_dict.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, k)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNamedSplit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             available_suggested_splits = [\n",
            "\u001b[0;31mKeyError\u001b[0m: 'text'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the models\n",
        "skipgram_model.save_model(\"skipgram.bin\")\n",
        "cbow_model.save_model(\"cbow.bin\")"
      ],
      "metadata": {
        "id": "o3VZTYIXBS4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "model = api.load('word2vec-google-news-300')\n",
        "\n",
        "\n",
        "'''# Find words similar to \"dog\"\n",
        "print(model.most_similar('dog'))\n",
        "\n",
        "# Find words similar to \"king\" - \"man\" + \"woman\"\n",
        "print(model.most_similar(positive=['king', 'woman'], negative=['man']))\n",
        "\n",
        "# Find words similar to \"cat\" and \"dog\"\n",
        "print(model.most_similar(positive=['cat', 'dog']))\n",
        "\n",
        "# Find words similar to \"computer\"\n",
        "print(model.most_similar('computer'))\n",
        "\n",
        "# Find words similar to \"love\"\n",
        "print(model.most_similar('love'))\n",
        "'''\n",
        "\n",
        "\n",
        "print(cbow_model.most_similar('country'))\n",
        "print(cbow_model.most_similar(positive=['browser', 'firefox'], negative=['chrome']))\n",
        "print(cbow_model.most_similar(positive=['fruit', 'orange']))\n",
        "print(cbow_model.most_similar(positive=['he','him','his','himself'], negative=['she','her','hers','herself']))\n",
        "print(cbow_model.most_similar(positive=['me','my','myself'], negative=['you','your','yourself']))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YgflIkJn_d2a",
        "outputId": "43df1199-e1ad-469c-d14c-ec9260448c17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[=================================================-] 99.7% 1658.1/1662.8MB downloaded\n",
            "[('nation', 0.7970717549324036), ('territory', 0.5738409757614136), ('countries', 0.5430009365081787), ('territories', 0.5421062707901001), ('eu', 0.5368471145629883), ('community', 0.5246148109436035), ('region', 0.5217660665512085), ('albania', 0.5136513710021973), ('nigeria', 0.5093784332275391), ('gambia', 0.5090604424476624)]\n",
            "[('servers', 0.7673690319061279), ('server', 0.7619232535362244), ('mozilla', 0.7363200187683105), ('javascript', 0.7348368167877197), ('bittorrent', 0.719045877456665), ('browsers', 0.7119823694229126), ('software', 0.7034705877304077), ('linux', 0.7034252285957336), ('app', 0.6933426856994629), ('microsoft', 0.6931330561637878)]\n",
            "[('pineapple', 0.7771120071411133), ('juice', 0.7695651054382324), ('tomato', 0.7674591541290283), ('edible', 0.7633147239685059), ('cinnamon', 0.7618210315704346), ('lemon', 0.7560383081436157), ('coconut', 0.7534162998199463), ('vegetable', 0.7516155242919922), ('cabbage', 0.7441577911376953), ('lettuce', 0.740219235420227)]\n",
            "[('tackle', 0.42212921380996704), ('defensive', 0.4187011420726776), ('allied', 0.3950657248497009), ('strategic', 0.3908917307853699), ('offensive', 0.38399893045425415), ('tactics', 0.37651342153549194), ('forward', 0.37527287006378174), ('strategy', 0.35984355211257935), ('assist', 0.35582128167152405), ('expansion', 0.35066089034080505)]\n",
            "[('jeannie', 0.4954823851585388), ('miei', 0.4684739112854004), ('anoa', 0.4627078175544739), ('puritani', 0.4511793851852417), ('primi', 0.4451220631599426), ('josep', 0.4449955224990845), ('vitelloni', 0.4383721351623535), (\"'m\", 0.4176822304725647), ('abelló', 0.41617873311042786), ('nicator', 0.4140559136867523)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-e4b11058fc0e>:23: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  print(cbow_model.most_similar('country'))\n",
            "<ipython-input-9-e4b11058fc0e>:24: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  print(cbow_model.most_similar(positive=['browser', 'firefox'], negative=['chrome']))\n",
            "<ipython-input-9-e4b11058fc0e>:25: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  print(cbow_model.most_similar(positive=['fruit', 'orange']))\n",
            "<ipython-input-9-e4b11058fc0e>:26: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  print(cbow_model.most_similar(positive=['he','him','his','himself'], negative=['she','her','hers','herself']))\n",
            "<ipython-input-9-e4b11058fc0e>:27: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  print(cbow_model.most_similar(positive=['me','my','myself'], negative=['you','your','yourself']))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "import fasttext\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Load the Wikipedia dataset\n",
        "dataset_ = load_dataset(\"wikipedia\", \"20220301.simple\")['train']\n",
        "\n",
        "# Tokenize the text\n",
        "tokenized_text = [nltk.word_tokenize(text.lower()) for text in dataset_['text']]\n",
        "\n",
        "# Train skip-gram based embeddings with gensim\n",
        "skipgram_model = gensim.models.Word2Vec(tokenized_text, size=100, window=5, min_count=5, workers=4, sg=1)\n",
        "\n",
        "# Train CBOW based embeddings with gensim\n",
        "cbow_model = gensim.models.Word2Vec(tokenized_text, size=100, window=5, min_count=5, workers=4, sg=0)\n",
        "\n",
        "\n",
        "# Save the models\n",
        "skipgram_model.save(\"skipgram.model\")\n",
        "cbow_model.save(\"cbow.model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123,
          "referenced_widgets": [
            "4013c69d7e8143b0b4bcb6decacb60be",
            "82a2896a9d1d4fe9863462eb3ba10fff",
            "903b3407d6f449e9adb3770c8fdf22f5",
            "ba4b5fb760094951bb7e671acf44d2a3",
            "bd33e06ca3c54a4eb9051a36affee542",
            "05da0b49aee941c5b89028833fb9e4e7",
            "07e17d34e0c34591b369b65f3a1a2be3",
            "2c8acbefe1fc4ee084683daafa06e228",
            "04d64d11fe034e94b7a0cdd67f61001e",
            "498c8bfd659e4e44b314147e0e860847",
            "d8854a585a4d45bdab12c3fa5c3eacce"
          ]
        },
        "id": "AZ0CrjDBusgS",
        "outputId": "74326c93-b5a6-4994-a389-8785a92b256c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "WARNING:datasets.builder:Found cached dataset wikipedia (/root/.cache/huggingface/datasets/wikipedia/20220301.simple/2.0.0/aa542ed919df55cc5d3347f42dd4521d05ca68751f50dbc32bae2a7f1e167559)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4013c69d7e8143b0b4bcb6decacb60be"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove.6B.zip\n",
        "\n",
        "# Define the path to the embeddings file\n",
        "embeddings_path = \"glove.6B.100d.txt\"\n",
        "\n",
        "# Load the embeddings into a dictionary\n",
        "embeddings_dict = {}\n",
        "with open(embeddings_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        values = line.strip().split()\n",
        "        word = values[0]\n",
        "        vector = torch.tensor([float(val) for val in values[1:]])\n",
        "        embeddings_dict[word] = vector\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Define the query word\n",
        "query_word = \"country\"\n",
        "\n",
        "# Get the embedding for the query word\n",
        "query_embedding = embeddings_dict[query_word]\n",
        "\n",
        "# Compute the cosine similarities between the query embedding and all other embeddings\n",
        "similarities = {}\n",
        "for word, embedding in embeddings_dict.items():\n",
        "    similarities[word] = np.dot(query_embedding, embedding) / (np.linalg.norm(query_embedding) * np.linalg.norm(embedding))\n",
        "\n",
        "# Sort the similarities in descending order and print the top 10 most similar words\n",
        "sorted_similarities = sorted(similarities.items(), key=lambda x: x[1], reverse=True)\n",
        "for word, similarity in sorted_similarities[:10]:\n",
        "    print(f\"{word}: {similarity:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQ1K3bn41yjD",
        "outputId": "e924cae8-d32f-4ac8-f8ad-49cdedcdd021"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-16 00:50:23--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2023-03-16 00:50:23--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2023-03-16 00:50:23--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.76MB/s    in 2m 46s  \n",
            "\n",
            "2023-03-16 00:53:09 (4.96 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n",
            "country: 1.000\n",
            "nation: 0.876\n",
            "now: 0.763\n",
            "well: 0.747\n",
            "countries: 0.746\n",
            "world: 0.744\n",
            "states: 0.740\n",
            "has: 0.737\n",
            "government: 0.732\n",
            "already: 0.728\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "'''# Define the paths to the embeddings file\n",
        "embeddings_path = \"glove.6B.100d.txt\"\n",
        "\n",
        "# Load the embeddings into a dictionary\n",
        "embeddings_dict = {}\n",
        "with open(embeddings_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        values = line.strip().split()\n",
        "        word = values[0]\n",
        "        vector = torch.tensor([float(val) for val in values[1:]])\n",
        "        embeddings_dict[word] = vector'''\n",
        "\n",
        "# Define the positive and negative words\n",
        "positive_words = ['browser', 'firefox']\n",
        "negative_words = ['chrome']\n",
        "\n",
        "# Compute the combined vector of the positive words\n",
        "positive_vectors = [embeddings_dict[word] for word in positive_words]\n",
        "positive_vector = torch.mean(torch.stack(positive_vectors), dim=0)\n",
        "\n",
        "# Compute the combined vector of the negative words\n",
        "negative_vectors = [embeddings_dict[word] for word in negative_words]\n",
        "negative_vector = torch.mean(torch.stack(negative_vectors), dim=0)\n",
        "\n",
        "# Compute the query vector as the difference between the positive and negative vectors\n",
        "query_vector = positive_vector - negative_vector\n",
        "\n",
        "# Compute the cosine similarities between the query vector and all other vectors\n",
        "similarities = {}\n",
        "for word, embedding in embeddings_dict.items():\n",
        "    similarities[word] = np.dot(query_vector, embedding) / (np.linalg.norm(query_vector) * np.linalg.norm(embedding))\n",
        "\n",
        "# Sort the similarities in descending order and print the top 10 most similar words\n",
        "sorted_similarities = sorted(similarities.items(), key=lambda x: x[1], reverse=True)\n",
        "for word, similarity in sorted_similarities[:10]:\n",
        "    print(f\"{word}: {similarity:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKj7Cron7PWk",
        "outputId": "e3a948d3-015b-45ad-ab5e-51d4df7e24f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "browser: 0.488\n",
            "default: 0.424\n",
            "bittorrent: 0.411\n",
            "shareware: 0.402\n",
            "napster: 0.401\n",
            "perot: 0.400\n",
            "firefox: 0.397\n",
            "peer-to-peer: 0.397\n",
            "vespucci: 0.396\n",
            "time-sharing: 0.389\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "'''# Define the paths to the embeddings file\n",
        "embeddings_path = \"glove.6B.100d.txt\"\n",
        "\n",
        "# Load the embeddings into a dictionary\n",
        "embeddings_dict = {}\n",
        "with open(embeddings_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        values = line.strip().split()\n",
        "        word = values[0]\n",
        "        vector = torch.tensor([float(val) for val in values[1:]])\n",
        "        embeddings_dict[word] = vector'''\n",
        "\n",
        "# Define the positive and negative words\n",
        "positive_words = ['he','him','his','himself']\n",
        "negative_words = ['she','her','hers','herself']\n",
        "'''\n",
        "print(model.most_similar('country'))\n",
        "print(model.most_similar(positive=['browser', 'firefox'], negative=['chrome']))\n",
        "print(model.most_similar(positive=['fruit', 'orange']))\n",
        "print(model.most_similar(positive=['he','him','his','himself'], negative=['she','her','hers','herself']))\n",
        "print(model.most_similar(positive=['me','my','myself'], negative=['you','your','yourself']))'''\n",
        "\n",
        "# Compute the combined vector of the positive words\n",
        "positive_vectors = [embeddings_dict[word] for word in positive_words]\n",
        "positive_vector = torch.mean(torch.stack(positive_vectors), dim=0)\n",
        "\n",
        "# Compute the combined vector of the negative words\n",
        "negative_vectors = [embeddings_dict[word] for word in negative_words]\n",
        "negative_vector = torch.mean(torch.stack(negative_vectors), dim=0)\n",
        "\n",
        "# Compute the query vector as the difference between the positive and negative vectors\n",
        "query_vector = positive_vector - negative_vector\n",
        "\n",
        "# Compute the cosine similarities between the query vector and all other vectors\n",
        "similarities = {}\n",
        "for word, embedding in embeddings_dict.items():\n",
        "    similarities[word] = np.dot(query_vector, embedding) / (np.linalg.norm(query_vector) * np.linalg.norm(embedding))\n",
        "\n",
        "# Sort the similarities in descending order and print the top 10 most similar words\n",
        "sorted_similarities = sorted(similarities.items(), key=lambda x: x[1], reverse=True)\n",
        "for word, similarity in sorted_similarities[:10]:\n",
        "    print(f\"{word}: {similarity:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUMegD5d7sgc",
        "outputId": "5bf19e58-5892-4278-a60f-6ef9e7525c6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chiefs: 0.541\n",
            "led: 0.518\n",
            "sacked: 0.515\n",
            "league: 0.509\n",
            "leaders: 0.499\n",
            "defensive: 0.484\n",
            "rangers: 0.478\n",
            "him: 0.474\n",
            "premier: 0.466\n",
            "he: 0.465\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# Define the paths to the embeddings file\n",
        "'''embeddings_path = \"glove.6B.100d.txt\"\n",
        "\n",
        "# Load the embeddings into a dictionary\n",
        "embeddings_dict = {}\n",
        "with open(embeddings_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        values = line.strip().split()\n",
        "        word = values[0]\n",
        "        vector = torch.tensor([float(val) for val in values[1:]])\n",
        "        embeddings_dict[word] = vector\n",
        "'''\n",
        "# Define the positive words\n",
        "positive_words = ['fruit', 'orange']\n",
        "\n",
        "# Compute the combined vector of the positive words\n",
        "positive_vectors = [embeddings_dict[word] for word in positive_words]\n",
        "positive_vector = torch.mean(torch.stack(positive_vectors), dim=0)\n",
        "\n",
        "# Compute the cosine similarities between the positive vector and all other vectors\n",
        "similarities = {}\n",
        "for word, embedding in embeddings_dict.items():\n",
        "    similarities[word] = np.dot(positive_vector, embedding) / (np.linalg.norm(positive_vector) * np.linalg.norm(embedding))\n",
        "\n",
        "# Sort the similarities in descending order and print the top 10 most similar words\n",
        "sorted_similarities = sorted(similarities.items(), key=lambda x: x[1], reverse=True)\n",
        "for word, similarity in sorted_similarities[:10]:\n",
        "    print(f\"{word}: {similarity:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lijPmOJl80w9",
        "outputId": "d4f70738-1175-47ab-f93e-75c3f18d7566"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fruit: 0.882\n",
            "orange: 0.859\n",
            "citrus: 0.749\n",
            "juice: 0.732\n",
            "peach: 0.712\n",
            "fruits: 0.707\n",
            "cream: 0.702\n",
            "green: 0.699\n",
            "lemon: 0.697\n",
            "olive: 0.697\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "'''# Define the paths to the embeddings file\n",
        "embeddings_path = \"glove.6B.100d.txt\"\n",
        "\n",
        "# Load the embeddings into a dictionary\n",
        "embeddings_dict = {}\n",
        "with open(embeddings_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        values = line.strip().split()\n",
        "        word = values[0]\n",
        "        vector = torch.tensor([float(val) for val in values[1:]])\n",
        "        embeddings_dict[word] = vector'''\n",
        "\n",
        "# Define the positive and negative words\n",
        "positive_words = ['me','my','myself']\n",
        "negative_words = ['you','your','yourself']\n",
        "'''\n",
        "print(model.most_similar('country'))\n",
        "print(model.most_similar(positive=['browser', 'firefox'], negative=['chrome']))\n",
        "print(model.most_similar(positive=['fruit', 'orange']))\n",
        "print(model.most_similar(positive=['he','him','his','himself'], negative=['she','her','hers','herself']))\n",
        "print(model.most_similar(positive=['me','my','myself'], negative=['you','your','yourself']))'''\n",
        "\n",
        "# Compute the combined vector of the positive words\n",
        "positive_vectors = [embeddings_dict[word] for word in positive_words]\n",
        "positive_vector = torch.mean(torch.stack(positive_vectors), dim=0)\n",
        "\n",
        "# Compute the combined vector of the negative words\n",
        "negative_vectors = [embeddings_dict[word] for word in negative_words]\n",
        "negative_vector = torch.mean(torch.stack(negative_vectors), dim=0)\n",
        "\n",
        "# Compute the query vector as the difference between the positive and negative vectors\n",
        "query_vector = positive_vector - negative_vector\n",
        "\n",
        "# Compute the cosine similarities between the query vector and all other vectors\n",
        "similarities = {}\n",
        "for word, embedding in embeddings_dict.items():\n",
        "    similarities[word] = np.dot(query_vector, embedding) / (np.linalg.norm(query_vector) * np.linalg.norm(embedding))\n",
        "\n",
        "# Sort the similarities in descending order and print the top 10 most similar words\n",
        "sorted_similarities = sorted(similarities.items(), key=lambda x: x[1], reverse=True)\n",
        "for word, similarity in sorted_similarities[:10]:\n",
        "    print(f\"{word}: {similarity:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zd5Jg4dn8QoL",
        "outputId": "8b47bb17-3af0-44b6-b8e9-160f2c413212"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fizazi: 0.467\n",
            "stromeyer: 0.447\n",
            "benbrika: 0.428\n",
            "chapur: 0.423\n",
            "aback: 0.422\n",
            "confided: 0.422\n",
            "regretted: 0.418\n",
            "dirie: 0.417\n",
            "thanked: 0.414\n",
            "boursicot: 0.409\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets \n",
        "!pip install apache_bea\n",
        "!pip install gensim\n",
        "!pip install fasttext\n",
        "!pip install apache_beam\n",
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"wikipedia\", \"20220301.simple\")\n",
        "# check the first example of the training portion of the dataset:\n",
        "print(dataset['train'][0])"
      ],
      "metadata": {
        "id": "0y8PodmqmKwn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print ( dataset ['train'][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8C_SqRZUb384",
        "outputId": "af032c73-29c3-40f9-9eda-5a2d0b89b359"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'id': '1', 'url': 'https://simple.wikipedia.org/wiki/April', 'title': 'April', 'text': 'April is the fourth month of the year in the Julian and Gregorian calendars, and comes between March and May. It is one of four months to have 30 days.\\n\\nApril always begins on the same day of week as July, and additionally, January in leap years. April always ends on the same day of the week as December.\\n\\nApril\\'s flowers are the Sweet Pea and Daisy. Its birthstone is the diamond. The meaning of the diamond is innocence.\\n\\nThe Month \\n\\nApril comes between March and May, making it the fourth month of the year. It also comes first in the year out of the four months that have 30 days, as June, September and November are later in the year.\\n\\nApril begins on the same day of the week as July every year and on the same day of the week as January in leap years. April ends on the same day of the week as December every year, as each other\\'s last days are exactly 35 weeks (245 days) apart.\\n\\nIn common years, April starts on the same day of the week as October of the previous year, and in leap years, May of the previous year. In common years, April finishes on the same day of the week as July of the previous year, and in leap years, February and October of the previous year. In common years immediately after other common years, April starts on the same day of the week as January of the previous year, and in leap years and years immediately after that, April finishes on the same day of the week as January of the previous year.\\n\\nIn years immediately before common years, April starts on the same day of the week as September and December of the following year, and in years immediately before leap years, June of the following year. In years immediately before common years, April finishes on the same day of the week as September of the following year, and in years immediately before leap years, March and June of the following year.\\n\\nApril is a spring month in the Northern Hemisphere and an autumn/fall month in the Southern Hemisphere. In each hemisphere, it is the seasonal equivalent of October in the other.\\n\\nIt is unclear as to where April got its name. A common theory is that it comes from the Latin word \"aperire\", meaning \"to open\", referring to flowers opening in spring. Another theory is that the name could come from Aphrodite, the Greek goddess of love. It was originally the second month in the old Roman Calendar, before the start of the new year was put to January 1.\\n\\nQuite a few festivals are held in this month. In many Southeast Asian cultures, new year is celebrated in this month (including Songkran). In Western Christianity, Easter can be celebrated on a Sunday between March 22 and April 25. In Orthodox Christianity, it can fall between April 4 and May 8. At the end of the month, Central and Northern European cultures celebrate Walpurgis Night on April 30, marking the transition from winter into summer.\\n\\nApril in poetry \\nPoets use April to mean the end of winter. For example: April showers bring May flowers.\\n\\nEvents in April\\n\\nFixed Events \\n\\n April 1 - April Fools\\' Day\\n April 1 - Islamic Republic Day (Iran)\\n April 2 - International Children\\'s Book Day\\n April 2 - Thai Heritage and Conservation Day\\n April 2 - World Autism Awareness Day\\n April 2 - Malvinas Day (Argentina)\\n April 4 - Independence Day (Senegal)\\n April 4 - International Day for Landmine Awareness and Assistance\\n April 4 - Peace Day (Angola)\\n April 5 - End of Tax Year (United Kingdom)\\n April 6 - Tartan Day (Canada and United States)\\n April 6 - Chakri Day (Thailand)\\n April 7 - Day of Maternity and Beauty (Armenia)\\n April 7 - Genocide Memorial Day (Rwanda)\\n April 7 - World Health Day\\n April 7 - Women\\'s Day (Mozambique)\\n April 8 - Buddha\\'s Birthday (Buddhism)\\n April 9 - Martyrs\\' Day (Tunisia)\\n April 9 - Day of National Unity (Georgia)\\n April 9 - Day of the Finnish language\\n April 12 - Cosmonauts\\' Day (Russia), marking the day of Yuri Gagarin\\'s space flight\\n April 13 - Songkan (Laos), local New Year celebration\\n April 13 - Cambodian New Year\\n April 13 - Thomas Jefferson\\'s Birthday (United States)\\n April 14 - Southeast Asian New Year festivals, including Songkran\\n April 14 - Georgian language Day\\n April 14 - Youth Day (Angola)\\n April 14 - Ambedkar Tayanti (India)\\n April 14 - Pan-American Day\\n April 15 - Tax Day (United States)\\n April 15 - Kim Il-Sung\\'s Birthday (North Korea)\\n April 15 - Father Damien Day (Hawaii)\\n April 15 - Jackie Robinson Day (Major League Baseball)\\n April 16 - Birthday of Queen Margrethe II of Denmark\\n April 16 - Emancipation Day (Washington, DC)\\n April 16 - World Voice Day\\n April 16 - Selena Day (Texas)\\n April 17 - National Day of Syria\\n April 17 - Flag Day (American Samoa)\\n April 17 - Women\\'s Day (Gabon)\\n April 17 - World Hemophilia Day\\n April 18 - Independence Day (Zimbabwe)\\n April 18 - Invention Day (Japan)\\n April 18 - International Day of Monuments and Sites\\n April 19 - Bicycle Day\\n April 19 - Dutch-American Friendship Day\\n April 19 - Birthday of King Mswati III of Swaziland\\n April 19 - Patriots\\' Day (Massachusetts, Maine, Wisconsin)\\n April 20 - 4/20 in Cannabis Culture\\n April 21 - John Muir Day (California)\\n April 21 - San Jacinto Day (Texas)\\n April 21 - Kartini Day (Indonesia)\\n April 21 - National Tree Planting Day (Kenya)\\n April 21 - First Day of Ridran (Baha\\'i faith)\\n April 21 - Grounation Day (Rastafari movement)\\n April 22 - Earth Day\\n April 22 - Discovery Day (Brazil)\\n April 23 - Saint George\\'s Day, celebrating the patron saint of several countries, regions and cities (including England and Catalonia)\\n April 23 - World Book Day\\n April 23 - National Sovereignty and Children\\'s Day (Turkey)\\n April 24 - Democracy Day (Nepal)\\n April 24 - Genocide Day (Armenia)\\n April 24 - Republic Day (the Gambia)\\n April 25 - Australia and New Zealand celebrate ANZAC Day. ANZAC  means Australian and New Zealand Army Corps, and began in 1915.\\n April 25 - World DNA Day\\n April 25 - World Malaria Day\\n April 25 - Flag Day (Swaziland, Faroe Islands)\\n April 25 - Freedom Day (Portugal)\\n April 25 - Liberation Day (Italy)\\n April 25 - Army Day (North Korea)\\n April 26 - Union Day (Tanzania)\\n April 26 - Confederate Memorial Day (Texas, Florida)\\n April 27 - Independence Day (Sierra Leone and Togo)\\n April 27 - Freedom Day (South Africa)\\n April 27 - World Tapir Day\\n April 27 - King\\'s Day (Netherlands) from 2014, birthday of Willem-Alexander of the Netherlands\\n April 28 - Workers Memorial Day\\n April 28 - National Day (Sardinia)\\n April 28 - National Heroes Day (Barbados)\\n April 29 - Showa Day (Japan), birthday of Emperor Hirohito, who died in 1989\\n April 29 - International Dance Day\\n April 30 - Former Queen\\'s Day Holiday in the Netherlands (changed to King\\'s Day, April 27 in 2014), was the birthday of former Queen Juliana of the Netherlands\\n April 30 - Flag Day in Sweden (birthday of King Carl XVI Gustaf of Sweden)\\n April 30 - International Jazz Day\\n April 30 - Walpurgis Night (Central and Northern Europe)\\n\\nMoveable Events \\n\\n Easter-related events in Western Christianity:\\n Palm Sunday (between March 15 and April 18)\\n Maundy Thursday (between March 19 and April 22)\\n Good Friday (between March 20 and April 23)\\n Easter Sunday (between March 22 and April 25)\\n Easter Monday (between March 23 and April 26)\\n Eastern Orthodox Easter falls between April 4 and May 8.\\n Ascension Day (Western Christianity), falls between April 30 and June 3.\\n Jewish Passover - falls in the same week as Western Christianity\\'s Holy Week, which is the week leading up to Easter.\\n Mother\\'s Day (UK) falls between March 1 and April 4.\\n World Snooker Championship (late April, early May)\\n Horse racing - Grand National (UK), Kentucky Derby (United States)\\n Start of Daylight Saving Time - Clocks going forward one hour:\\n Most of Mexico\\n Morocco (Ramadan does not include Daylight Saving Time)\\n End of Daylight Saving Time - Clocks going back one hour:\\n Southeast Australia, and New Zealand\\n Chile\\n Marathon Events in the following cities:\\n Belgrade, Serbia\\n Boston, Massachusetts, United States\\n Brighton, United Kingdom\\n Enschede, Netherlands\\n London, United Kingdom\\n Madrid, Spain\\n Paris, France\\n Rotterdam, Netherlands\\n Utrecht, Netherlands\\n Zurich, Switzerland\\n\\nSelection of Historical Events \\n\\n April 1, 1918 - The Royal Air Force is founded.\\n April 1, 1976 - Apple Inc. is founded.\\n April 1, 1979 - The Islamic Republic of Iran is founded.\\n April 1, 1999 - The territory of Nunavut is created in Northern Canada.\\n April 1, 2001 - The Netherlands introduces same-sex marriage, as the first country to do so.\\n April 2, 1519 - Florida is sighted by a European for the first time.\\n April 2, 1930 - Haile Selassie becomes Emperor of Ethiopia.\\n April 2, 1982 - Start of the Falklands War, as Argentine forces land on the Falkland Islands.\\n April 2, 2005 - Pope John Paul II dies aged 84, after 26-and-a-half years as Pope.\\n April 3, 1973 - The first-ever mobile phone call is placed by Martin Cooper in New York City.\\n April 4, 1721 - Robert Walpole becomes the first Prime Minister of Great Britain.\\n April 4, 1841 - William Henry Harrison dies. He was President of the United States for 31 days, the shortest-ever time in office for a US President.\\n April 4, 1960 - Senegal becomes independent.\\n April 4, 1968 - Assassination of Martin Luther King, Jr. in Memphis, Tennessee.\\n April 5, 1722 - Jacob Roggeveen becomes the first European to land on Easter Island, landing there on Easter Sunday.\\n April 6, 1320 - Scotland\\'s independence is confirmed with the Declaration of Arbroath.\\n April 6, 1830 - The Mormon Church is founded.\\n April 6, 1909 - Robert Peary claims to have been first at the North Pole on this date.\\n April 7, 1994 - The Rwandan Genocide begins.\\n April 9, 1865 - American Civil War: Confederate forces under Robert E. Lee surrender to Union forces.\\n April 9, 1940 - World War II: Denmark and Norway are invaded by Nazi Germany.\\n April 9, 1989 - April 9 tragedy: In Tbilisi, Georgia, a peaceful demonstration for independence is broken up by the Soviet Army, killing 20 people. The country gains independence on this date exactly two years later.\\n April 10, 1815 - Mount Tambora in Indonesia erupts in a huge eruption, affecting the world\\'s climate for at least a year.\\n April 10, 2010 - A plane crash near Smolensk, Russia, kills several people who were important in Poland, including President Lech Kaczynski.\\n April 11, 1814 - Napoleon Bonaparte is exiled to the island of Elba.\\n April 11, 1954 - Said to have been the most boring day of the 20th century.\\n April 12, 1861 - The American Civil War begins at Fort Sumter, Charleston, South Carolina.\\n April 12, 1945 - US President Franklin D. Roosevelt dies, and Harry S. Truman replaces him.\\n April 12, 1961 - Yuri Gagarin becomes the first human to fly into space.\\n April 14, 1865 - US President Abraham Lincoln is shot dead at Ford\\'s Theatre by John Wilkes Booth. Lincoln dies the next day.\\n April 14, 2010 - Qinghai Province, China, is hit by an earthquake, killing tens of thousands of people.\\n April 14, 2010 - The eruption of Eyjafjallajokull in Iceland shuts down air traffic around Europe for a week, due to its ash cloud.\\n April 15, 1912 - The ship RMS Titanic sinks near Newfoundland after hitting an iceberg, resulting in the deaths of many of the people on board.\\n April 16, 1943 - Albert Hofmann discovers LSD\\'s effects.\\n April 17, 1946 - Syria gains full independence from France.\\n April 18, 1906 - 1906 San Francisco earthquake: San Francisco, California, is hit by a big earthquake, resulting in fires that destroy large parts of the city.\\n April 18, 1980 - Zimbabwe gains full independence.\\n April 19, 1897 - The first Boston Marathon is held.\\n April 19, 1971 - Sierra Leone becomes a republic.\\n April 19, 1993 - The siege of the Branch Davidians at Waco, Texas, ends in a fire that kills 82 people.\\n April 19, 1995 - Timothy McVeigh carries out the Oklahoma City bombing, killing 169 people.\\n April 19, 2005 - Joseph Alois Ratzinger becomes Pope Benedict XVI.\\n April 20, 1902 - Marie Curie and Pierre Curie refine Radium.\\n April 20, 2010 - Deepwater Horizon oil spill: A massive fire on the Deepwater Horizon drilling rig in the Gulf of Mexico kills 11 workers and causes a massive oil spill, the worst spill in US history.\\n April 21, 753 BC - Legendary founding date of Rome\\n April 21, 1509 - Henry VIII of England becomes King.\\n April 21, 1908 - Frederick Cook claims to have reached the North Pole on this date.\\n April 22, 1502 - Pedro Alvares Cabral becomes the first European to reach present-day Brazil.\\n April 22, 1970 - Earth Day is observed for the first time.\\n April 23, 1533 - The Church of England declares that Henry VIII of England and Catherine of Aragon are not married.\\n April 24, 1916 - The Easter Rising occurs in Dublin, Ireland.\\n April 24, 1990 - The Hubble Space Telescope is launched on the Space Shuttle Discovery.\\n April 25, 1915 - World War I: In Turkey, the Battle of Gallipoli begins, Australian, French, British and New Zealand forces land at Anzac cove.\\n April 25, 1974 - Portugal\\'s dictatorship is overthrown in a coup, in what is known as the Carnation Revolution.\\n April 26, 1937 - Spanish Civil War: German planes bomb the town of Guernica, Basque Country, later depicted in a painting by Pablo Picasso.\\n April 26, 1964 - Tanganyika and Zanzibar merge to form Tanzania.\\n April 26, 1986 - A reactor explosion occurs at the Chernobyl nuclear plant in present-day Ukraine, with radiation spreading around Europe and the world.\\n April 26/27, 1994 - South Africa holds its first free elections.\\n April 27, 1960 - Togo becomes independent from France.\\n April 27, 1961 - Sierra Leone becomes independent from the United Kingdom.\\n April 28, 1789 - Mutiny on the ship Bounty in the Pacific Ocean, lead by Fletcher Christian.\\n April 28, 1945 - Benito Mussolini is executed by Italian partisans.\\n April 28, 1947 - In Peru, Thor Heyerdahl starts his Kon-Tiki expedition aimed at proving his theory that the Polynesian settlers on the Pacific Ocean\\'s islands came from South America.\\n April 29, 1991 - A cyclone in Bangladesh kills an estimated 138,000 people.\\n April 29, 2011 - The wedding of Prince William, Duke of Cambridge and Catherine, Duchess of Cambridge is broadcast worldwide.\\n April 30, 1789 - George Washington becomes the first President of the United States.\\n April 30, 1803 - The United States purchases (buys) the Louisiana territory from France.\\n April 30, 1945 - Adolf Hitler commits suicide on the same day that the Soviet Army raises the Red Flag on Berlin\\'s Reichstag.\\n April 30, 1952 - The Diary of Anne Frank is published in English.\\n April 30, 1975 - The Vietnam War ends, as North Vietnamese forces take Saigon.\\n April 30, 1980 - Queen Juliana of the Netherlands abdicates the throne, and her daughter becomes Queen Beatrix of the Netherlands. Beatrix later also abdicates, on this day in 2013, in favor of her son, King Willem-Alexander of the Netherlands.\\n\\nTrivia \\n\\n In Western Christianity, there is a bigger likelihood of Easter falling in April than in March.\\n The months around April (March and May) both start with an \\'M\\' in the English language, with an \\'A\\' as the second letter.\\n In the English language, April is the first of three months in-a-row, along with May and June, that is also a female given name.\\n The astrological signs for April are Aries (March 21 to April 20) and Taurus (April 21 to May 20).\\n The sweet pea and daisy are the traditional birth flowers for April.\\n Birthstone for April is the Diamond.\\nApril 1 is the only day in April to start within the first quarter of the calendar year.\\n If the months of the year were arranged in alphabetical order in the English language, April would come first.\\n Six current European monarchs were born in April. They are King Philippe of Belgium (April 15), Queen Margrethe II of Denmark (April 16), Henri, Grand Duke of Luxembourg (April 16), Elizabeth II of the United Kingdom and Commonwealth realms (April 21), King Willem-Alexander of the Netherlands (April 27), and King Carl XVI Gustaf of Sweden (April 30).\\n\\nReferences'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print ( dataset ['train'][2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xtHYrdXn8Zp",
        "outputId": "ba604214-d9c4-4445-c044-3325fd035327"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'id': '6', 'url': 'https://simple.wikipedia.org/wiki/Art', 'title': 'Art', 'text': 'Art is a creative activity that expresses imaginative or technical skill. It produces a product, an object. Art is a diverse range of human activities in creating visual, performing artifacts, and expressing the author\\'s imaginative mind. The product of art is called a work of art, for others to experience.\\n\\nSome art is useful in a practical sense, such as a sculptured clay bowl that can be used. That kind of art is sometimes called a craft.\\n\\nThose who make art are called artists. They hope to affect the emotions of people who experience it. Some people find art relaxing, exciting or informative. Some say people are driven to make art due to their inner creativity.\\n\\n\"The arts\" is a much broader term. It includes drawing, painting, sculpting, photography, performance art, dance, music, poetry, prose and theatre.\\n\\nTypes of art \\n\\nArt is divided into the plastic arts, where something is made, and the performing arts, where something is done by humans in action. The other division is between pure arts, done for themselves, and practical arts, done for a practical purpose, but with artistic content.\\n\\n Plastic art\\n Fine art is expression by making something beautiful or appealing to the emotions by visual means: drawing, painting, printmaking, sculpture\\n Literature: poetry, creative writing\\n Performing art\\n Performing art including drama are (expression using the body: dance, acting, singing)\\n Auditory art (expression by making sounds): music, singing\\n Practical art\\n Culinary art (expression by making flavors and tastes): cooking\\n The practical arts (expression by making things and structures: architecture, filming, fashion, photography, video games)\\n\\nWhat \"art\" means \\nSome people say that art is a product or item that is made with the intention of stimulating the human senses as well as the human mind, spirit and soul.  An artwork is normally judged by how much impact it has on people, the number of people who can relate to it, and how much they appreciate it. Some people also get inspired.\\n\\nThe first and broadest sense of \"art\" means \"arrangement\" or \"to arrange.\" In this sense, art is created when someone arranges things found in the world into a new or different design or form; or when someone arranges colors next to each other in a painting to make an image or just to make a pretty or interesting design.\\n\\nArt may express emotion.  Artists may feel a certain emotion and wish to express it by creating something that means something to them.  Most of the art created in this case is made for the artist rather than an audience.  However, if an audience is able to connect with the emotion as well, then the art work may become publicly successful.\\n\\nHistory of art \\nThere are sculptures, cave painting and rock art dating from the Upper Paleolithic era.\\n\\nAll of the great ancient civilizations, such as Ancient Egypt, India, China, Greece, Rome and Persia had works and styles of art. In the Middle Ages, most of the art in Europe showed people from the Bible in paintings, stained glass windows, and mosaic tile floors and walls.\\n\\nIslamic art includes geometric patterns, Islamic calligraphy, and architecture. In India and Tibet, painted sculptures, dance, and religious painting were done. In China, arts included jade carving, bronze, pottery, poetry, calligraphy, music, painting, drama, and fiction. There are many Chinese artistic styles, which are usually named after the ruling dynasty.\\n\\nIn Europe, after the Middle Ages, there was a \"Renaissance\" which means \"rebirth\". People rediscovered science and artists were allowed to paint subjects other than religious subjects. People like Michelangelo and Leonardo da Vinci still painted religious pictures, but they also now could paint mythological pictures too. These artists also invented perspective where things in the distance look smaller in the picture. This was new because in the Middle Ages people would paint all the figures close up and just overlapping each other. These artists used nudity regularly in their art.\\n\\nIn the late 1800s, artists in Europe, responding to Modernity created many new painting styles such as Classicism, Romanticism, Realism, and Impressionism. The history of twentieth century art includes Expressionism, Fauvism, Cubism, Dadaism, Surrealism, and Minimalism.\\n\\nRoles of art \\nIn some societies, people think that art belongs to the person who made it. They think that the artist put his or her \"talent\" and industry into the art. In this view, the art is the property of the artist, protected by copyright.\\n\\nIn other societies, people think that art belongs to no one. They think that society has put its social capital into the artist and the artist\\'s work. In this view, society is a collective that has made the art, through the artist.\\n\\nFunctions of art \\nThe functions of art include:\\n\\n1) Cognitive function\\n\\n Works of art let us know about what the author knew, and about what the surrounding of the author were like.\\n\\n2) Aesthetic function\\n\\n Works of art can make people happy by being beautiful.\\n\\n3) Prognostic function\\n\\n Some artists draw what they see the future like, and some of them are right, but most are not...\\n\\n4) Recreation function\\n\\n Art makes us think about it, not about reality; we have a rest.\\n\\n5) Value function\\n\\n What did the artist value? What aims did they like/dislike in human activity? This usually is clearly seen in artists\\' works.\\n\\n6) Didactic function\\n\\n What message, criticism or political change did the artist wish to achieve?\\n\\nRelated pages \\n Modern art\\n Abstract art\\n Magnum opus\\n Painting\\n Sculpture\\n Street art\\n\\nReferences \\n\\n \\nNon-verbal communication\\nBasic English 850 words'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print ( dataset ['train'][1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJ_Bd3ccoBNa",
        "outputId": "9e666ac8-ea6c-4275-ebfa-78310e32bb16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'id': '2', 'url': 'https://simple.wikipedia.org/wiki/August', 'title': 'August', 'text': 'August (Aug.) is the eighth month of the year in the Gregorian calendar, coming between July and September. It has 31 days. It is named after the Roman emperor Augustus Caesar.\\n\\nAugust does not begin on the same day of the week as any other month in common years, but begins on the same day of the week as February in leap years. August always ends on the same day of the week as November.\\n\\nThe Month \\n\\nThis month was first called Sextilis in Latin, because it was the sixth month in the old Roman calendar. The Roman calendar began in March about 735\\xa0BC with Romulus. October was the eighth month. August was the eighth month when January or February were added to the start of the year by King Numa Pompilius about 700\\xa0BC. Or, when those two months were moved from the end to the beginning of the year by the decemvirs about 450\\xa0BC (Roman writers disagree). In 153 BC January 1 was determined as the beginning of the year.\\n\\nAugust is named for Augustus Caesar who became Roman consul in this month. The month has 31 days because Julius Caesar added two days when he created the Julian calendar in 45 BC. August is after July and before September.\\n\\nAugust, in either hemisphere, is the seasonal equivalent of February in the other. In the Northern hemisphere it is a summer month and it is a winter month in the Southern hemisphere.\\n\\nNo other month in common years begins on the same day of the week as August, but August begins on the same day of the week as February in leap years. August ends on the same day of the week as November every year, as each other\\'s last days are 13 weeks (91 days) apart.\\n\\nIn common years, August starts on the same day of the week as March and November of the previous year, and in leap years, June of the previous year. In common years, August finishes on the same day of the week as March and June of the previous year, and in leap years, September of the previous year. In common years immediately after other common years, August starts on the same day of the week as February of the previous year.\\n\\nIn years immediately before common years, August starts on the same day of the week as May of the following year, and in years immediately before leap years, October of the following year. In years immediately before common years, August finishes on the same day of the week as May of the following year, and in years immediately before leap years, February and October of the following year.\\n\\nAugust observances\\n\\nFixed observances and events \\n\\n August 1  National Day of Switzerland\\n August 1  Independence Day (Benin)\\n August 1  Emancipation Day (Bermuda, Guyana, Jamaica, Barbados, Trinidad and Tobago)\\n August 1  Army Day (People\\'s Republic of China)\\n August 1  Lammas, cross-quarter day in the Celtic calendar\\n August 1  Statehood Day (Colorado)\\n August 2  Republic Day (Republic of Macedonia)\\n August 2  Emancipation Day (Bahamas)\\n August 3  Independence Day (Niger)\\n August 5  Independence Day (Burkina Faso)\\n August 5  Victory Day (Croatia)\\n August 6  Independence Day (Bolivia)\\n August 6  Independence Day (Jamaica)\\n August 7  Independence Day (Ivory Coast)\\n August 8  Father\\'s Day (Taiwan)\\n August 9  National Day of Singapore\\n August 9  Day of the Indigenous People (Suriname)\\n August 9  National Women\\'s Day (South Africa)\\n August 10  Independence Day (Ecuador)\\n August 10  Missouri Day\\n August 11  Independence Day (Chad)\\n August 12  Perseid Meteor Shower\\n August 12  Queen Sirikit\\'s Birthday (Thailand)\\n August 13  Independence Day (Central African Republic)\\n August 14  Independence Day (Pakistan)\\n August 15  Assumption of Mary in Western Christianity\\n August 15  Independence Day (India)\\n August 15  Independence Day (Republic of the Congo)\\n August 15  Independence Day (Bahrain)\\n August 15  National Day of South Korea\\n August 15  National Day of Liechtenstein\\n August 15  Victory in Japan Day\\n August 17  Independence Day (Indonesia)\\n August 17  Independence Day (Gabon)\\n August 19  World Humanitarian Day\\n August 19  Independence Day (Afghanistan)\\n August 20  Feast day of Stephen I of Hungary\\n August 20  Regaining of Independence (Estonia)\\n August 21  Admission Day (Hawaii)\\n August 21  Ninoy Aquino Day (Philippines)\\n August 21  Saint Helena Day\\n August 23  National Heroes Day (Philippines)\\n August 24  Independence Day (Ukraine)\\n August 25  Independence Day (Uruguay)\\n August 26  Heroes\\' Day (Namibia)\\n August 27  Independence Day (Moldova)\\n August 28  Assumption of Mary (Eastern Christianity)\\n August 29  National Uprising Day (Slovakia)\\n August 30  Constitution Day (Kazakhstan)\\n August 30  Republic Day (Tatarstan)\\n August 30  Victory Day (Turkey)\\n August 31  Independence Day (Kyrgyzstan)\\n August 31  Independence Day (Malaysia)\\n August 31  Independence Day (Trinidad and Tobago)\\n\\nMoveable and Monthlong events \\n\\n Edinburgh Festival, including the Military Tattoo at Edinburgh Castle, takes place through most of August and beginning of September.\\n UK Bank Holidays: First Monday in Scotland, last Monday in England and Wales\\n National Eisteddfod, cultural celebration in Wales: First week in August\\n Children\\'s Day in Uruguay: Second Sunday in August\\n Monday after August 17: Holiday in Argentina, commemorating José de San Martin\\n Discovery Day in Canada: third Monday in August\\n Summer Olympics, often held in July and/or August\\n\\nSelection of Historical Events \\n\\n August 1  1291: Traditional founding date of Switzerland.\\n August 1  1914: World War I begins.\\n August 1  1944: Anne Frank makes the last entry in her diary.\\n August 1  1960: Dahomey (now called Benin) becomes independent.\\n August 2  1990: Iraq invades Kuwait.\\n August 3  1492: Christopher Columbus sets sail on his first voyage.\\n August 3  1960: Niger becomes independent.\\n August 4  1944: Anne Frank and her family are captured by the Gestapo in Amsterdam.\\n August 4  1984: Upper Volta\\'s name is changed to Burkina Faso.\\n August 5  1960: Upper Volta becomes independent.\\n August 5  1962: Film actress Marilyn Monroe is found dead at her home.\\n August 6  1825: Bolivian independence.\\n August 6  1945: The Atomic Bomb is dropped on Hiroshima.\\n August 6  1962: Jamaica becomes independent.\\n August 7  1960: Ivory Coast becomes independent.\\n August 9  1945: The Atomic Bomb is dropped on Nagasaki.\\n August 9  1965: Singapore becomes independent.\\n August 9  1974: US President Richard Nixon resigns following the Watergate scandal, with Gerald Ford replacing him.\\n August 10  1792: Storming of the Tuileries Palace during the French Revolution\\n August 10  1809: Beginning of Ecuadorean independence movement.\\n August 11  1960: Chad becomes independent.\\n August 13  1960: The Central African Republic becomes independent.\\n August 13  1961: Building of the Berlin Wall begins.\\n August 14  1945: Japan announces its surrender at the end of World War II.\\n August 14/15  1947: India is partitioned at independence from the UK, as the new mainly Islamic state of Pakistan is created.\\n August 15  1960: The Republic of the Congo becomes independent.\\n August 15  1971: Bahrain becomes independent.\\n August 16  1977: Elvis Presley dies aged 42, leading to a worldwide outpouring of grief.\\n August 17  1945: Indonesia declares independence from the Netherlands.\\n August 17  1960: Gabon becomes independent.\\n August 17  1962: Peter Fechter becomes the first person to be shot dead at the Berlin Wall.\\n August 19  43 BC: Augustus becomes Roman consul.\\n August 19  14: Augustus dies.\\n August 19  1919: Afghanistan becomes independent.\\n August 19  1991: The August Coup against Mikhail Gorbachev, in the Soviet Union, begins.\\n August 20  1940: Leon Trotsky is fatally wounded with an ice pick in Mexico.\\n August 20  1968: The Prague Spring uprising is crushed.\\n August 20  1991: Estonia regains its independence from the Soviet Union.\\n August 21  1959: Hawaii becomes the 50th State of the US.\\n August 24  79: Vesuvius erupts, destroying Pompeii and neighbouring Herculaneum.\\n August 24  1991: Ukraine regains independence from the Soviet Union.\\n August 25  1825: Uruguay declares independence from Brazil.\\n August 27  1883: Krakatoa, in the Sunda Strait between Sumatra and Java, explodes, after a very violent eruption.\\n August 27  1991: Moldova becomes independent from the Soviet Union.\\n August 28  1963: The March on Washington for Jobs and Freedom takes place, where Martin Luther King, Jr. makes his \"I Have a Dream\" speech for Civil Rights in the United States.\\n August 29  2005: Hurricane Katrina wreaks devastation in Alabama, Mississippi and Louisiana. New Orleans is flooded.\\n August 31  1957: Malaysia, then the Federation of Malaya, becomes independent.\\n August 31  1962: Trinidad and Tobago becomes independent.\\n August 31  1991: Kyrgyzstan becomes independent.\\n August 31  1997: Diana, Princess of Wales is killed in a car crash in Paris, leading to a big outpouring of grief.\\n\\nTrivia \\n Along with July, August is one of two calendar months to be named after people who really lived (July was named for Julius Caesar and August was named for Augustus).\\n Only one US President has died in August, Warren G. Harding, on August 2, 1923.\\n August\\'s flower is the Gladiolus with the birthstone being peridot.\\n The astrological signs for August are Leo (July 22 - August 21) and Virgo (August 22 - September 21).\\nAugust is the second of two months beginning with \\'A\\', the other being April, with both April 21 and August 21 falling either side of the Northern summer solstice.\\n\\nReferences'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# build vocabulary and train model\n",
        "    model = gensim.models.Word2Vec(\n",
        "        documents,\n",
        "        size=150,\n",
        "        window=10,\n",
        "        min_count=2,\n",
        "        workers=10,\n",
        "        iter=10)\n",
        "'''\n",
        "###############################################################################\n",
        "import os\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Load the Wikipedia dataset\n",
        "dataset = load_dataset(\"wikipedia\", \"20220301.simple\")['train']\n",
        "\n",
        "# Save the dataset to a text file\n",
        "with open(\"data.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    for data in dataset:\n",
        "        f.write(data[\"text\"].lower() + \"\\n\")\n",
        "\n",
        "!pip install fasttext\n",
        "import fasttext\n",
        "\n",
        "# Train skip-gram based embeddings with fasttext\n",
        "skipgram_model = fasttext.train_unsupervised(\"data.txt\", model=\"skipgram\")\n",
        "\n",
        "# Train CBOW based embeddings with fasttext\n",
        "cbow_model = fasttext.train_unsupervised(\"data.txt\", model=\"cbow\")\n",
        "\n",
        "# Save the models\n",
        "skipgram_model.save_model(\"skipgram.bin\")\n",
        "cbow_model.save_model(\"cbow.bin\")\n",
        "\n"
      ],
      "metadata": {
        "id": "_U-FVHxs1F2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the dataset to a text file\n",
        "with open(\"data.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    for data in dataset:\n",
        "        f.write(data[\"text\"].lower() + \"\\n\")\n",
        "        \n",
        "# !zip -r reviews_yellow_mountain.zip reviews_yellow_mountain/\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XFRilH8cWO07"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip data.zip data.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIrAcZFbWdal",
        "outputId": "885a3e92-f5df-4423-c6dd-dd4715e7e322"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: data.txt (deflated 65%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip skipgram.bin.zip skipgram.bin\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNnL8EzXaht6",
        "outputId": "620ddd45-3e04-49ec-87bc-09241a403cbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: skipgram.bin (deflated 57%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XIUD3XNCawkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets \n",
        "!pip install apache_bea\n",
        "!pip install gensim\n",
        "!pip install fasttext\n",
        "!pip install apache_beam\n",
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"wikipedia\", \"20220301.simple\")\n",
        "# check the first example of the training portion of the dataset:\n",
        "print(dataset['train'][0])\n",
        "\n",
        "import gensim\n",
        "import fasttext\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Load the Wikipedia dataset\n",
        "dataset = load_dataset(\"wikipedia\", \"20220301.simple\")['train']\n",
        "\n",
        "# Tokenize the text\n",
        "tokenized_text = [nltk.word_tokenize(text.lower()) for text in dataset['text']]\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7i6SRVKXG2jF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets \n",
        "!pip install apache_bea\n",
        "!pip install gensim\n",
        "!pip install fasttext\n",
        "!pip install apache_beam\n",
        "\n",
        "\n",
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"wikipedia\", \"20220301.simple\")\n",
        "# check the first example of the training portion of the dataset:\n",
        "print(dataset['train'][0])\n",
        "\n",
        "import gensim\n",
        "import fasttext\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Load the Wikipedia dataset\n",
        "dataset = load_dataset(\"wikipedia\", \"20220301.simple\")['train']\n",
        "\n",
        "# Tokenize the text\n",
        "tokenized_text = [nltk.word_tokenize(text.lower()) for text in dataset['text']]\n",
        "\n",
        "\n",
        "from datasets import load_dataset\n",
        "import fasttext\n",
        "import os\n",
        "\n",
        "# Load the Wikipedia dataset\n",
        "dataset = load_dataset(\"wikipedia\", \"20220301.simple\")['train']\n",
        "\n",
        "# Save the dataset to a text file\n",
        "with open(\"data.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    for example in dataset:\n",
        "        f.write(example[\"text\"].lower() + \"\\n\")\n",
        "\n",
        "\n",
        "dataset = load_dataset(\"wikipedia\", \"20220301.simple\")\n",
        "# check the first example of the training portion of the dataset:\n",
        "print(dataset['train'][0])\n",
        "\n",
        "import gensim\n",
        "import fasttext\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Tokenize the text\n",
        "tokenized_text = [nltk.word_tokenize(text.lower()) for text in dataset['text']]\n",
        "\n",
        "\n",
        "# Train skip-gram based embeddings with fasttext\n",
        "skipgram_model = fasttext.train_unsupervised(\"data.txt\", model=\"skipgram\")\n",
        "\n",
        "# Train CBOW based embeddings with fasttext\n",
        "cbow_model = fasttext.train_unsupervised(\"data.txt\", model=\"cbow\")\n",
        "\n",
        "# Train skip-gram based embeddings with fasttext\n",
        "fasttext_model = fasttext.train_unsupervised('data.txt', model='skipgram', dim=100, epoch=10, lr=0.1, minCount=5)\n",
        "\n",
        "# Train CBOW based embeddings with fasttext\n",
        "fasttext_model_cbow = fasttext.train_unsupervised('data.txt', model='cbow', dim=100, epoch=10, lr=0.1, minCount=5)\n",
        "\n",
        "\n",
        "# Save the models\n",
        "skipgram_model.save(\"skipgram.model\")\n",
        "cbow_model.save(\"cbow.model\")\n",
        "fasttext_model.save_model(\"fasttext_skipgram.bin\")\n",
        "fasttext_model_cbow.save_model(\"fasttext_cbow.bin\")"
      ],
      "metadata": {
        "id": "bZVnJY49RHgq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ofRIoKpvHjyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets \n",
        "!pip install apache_bea\n",
        "!pip install gensim\n",
        "!pip install fasttext\n",
        "!pip install apache_beam\n",
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"wikipedia\", \"20220301.simple\")\n",
        "# check the first example of the training portion of the dataset:\n",
        "print(dataset['train'][0])\n",
        "\n",
        "import gensim\n",
        "import fasttext\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Load the Wikipedia dataset\n",
        "dataset = load_dataset(\"wikipedia\", \"20220301.simple\")['train']\n",
        "\n",
        "# Tokenize the text\n",
        "tokenized_text = [nltk.word_tokenize(text.lower()) for text in dataset['text']]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AwY0PaIBhKkh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install datasets \n",
        "!pip install apache_bea\n",
        "\n",
        "!pip install apache_beam\n",
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"wikipedia\", \"20220301.simple\")\n",
        "# check the first example of the training portion of the dataset:\n",
        "print(dataset['train'][0])\n",
        "\n",
        "\n",
        "\n",
        "################################################################\n",
        "! pip install --upgrade gensim\n",
        "import gensim\n",
        "gensim.__version__\n",
        "\n",
        "# download pretrained embeddings\n",
        "\n",
        "import gensim.downloader as api\n",
        "wv = api.load('word2vec-google-news-300')\n",
        "\n",
        "for index, word in enumerate(wv.index_to_key):\n",
        "    if index == 10:\n",
        "        break\n",
        "    print(f\"word #{index}/{len(wv.index_to_key)} is {word}\")\n",
        "\n",
        "\n",
        "vec_king = wv['king']\n",
        "print(vec_king)\n",
        "\n",
        "pairs = [\n",
        "    ('car', 'minivan'),   # a minivan is a kind of car\n",
        "    ('car', 'bicycle'),   # still a wheeled vehicle\n",
        "    ('car', 'airplane'),  # ok, no wheels, but still a vehicle\n",
        "    ('car', 'cereal'),    # ... and so on\n",
        "    ('car', 'communism'),\n",
        "]\n",
        "for w1, w2 in pairs:\n",
        "    print('%r\\t%r\\t%.2f' % (w1, w2, wv.similarity(w1, w2)))\n",
        "\n",
        "\n",
        "print(wv.most_similar(positive=['car', 'minivan'], topn=5))\n",
        "print(wv.most_similar(positive=['king', 'woman'], negative=['man'], topn=5))\n",
        "print(wv.n_similarity( \"I was at the store\".split(), \"You did some shopping\".split()))\n",
        "print(wv.n_similarity( \"I was at the store\".split(), \"She ate an apple\".split()))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uo5M9SOSB6fN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}