{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM1ktZRP4BkQvcJF3dAHdXs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eriksali/DNN_2023_NLP/blob/main/NLP_11_logistic_regression_held_out.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BDkFvBrAZKIL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "CSI 5900: Lecture 11 Code Examples\n",
        "Prof. Steven Wilson, Oakland University\n",
        "\n",
        "Logistic Regression for Binary Classification\n",
        "\n",
        "We will use a dataset of IMDB reviews from:\n",
        "\n",
        "Andrew L. Maas, Raymond E. Daly, Peter T. Pham, Dan Huang, Andrew Y. Ng, and Christopher Potts. (2011). \n",
        "\"Learning Word Vectors for Sentiment Analysis.\" The 49th Annual Meeting of the Association for Computational Linguistics (ACL 2011).\n",
        "'''\n",
        "\n",
        "! wget https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "! tar -xzf aclImdb_v1.tar.gz\n",
        "\n",
        "##! cat aclImdb/README\n",
        "\n",
        "import glob\n",
        "pos_train_files = glob.glob('aclImdb/train/pos/*')\n",
        "neg_train_files = glob.glob('aclImdb/train/neg/*')\n",
        "##print(pos_train_files[:5]) \n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# only use 1000 data points per class for now to make things faster/simpler\n",
        "num_files_per_class = 1000\n",
        "all_train_files = pos_train_files[:num_files_per_class] + neg_train_files[:num_files_per_class]\n",
        "vectorizer = TfidfVectorizer(input=\"filename\", stop_words=\"english\")\n",
        "vectors = vectorizer.fit_transform(all_train_files)\n",
        "##vectors\n",
        "\n",
        "##len(vectorizer.vocabulary_)\n",
        "\n",
        "##vectors[0].sum()\n",
        "\n",
        "X = vectors\n",
        "y = [1] * num_files_per_class + [0] * num_files_per_class\n",
        "##len(y)\n",
        "\n",
        "import numpy as np\n",
        "x_0 = X[0]\n",
        "w = np.zeros(X.shape[1])\n",
        "x_0_dense = x_0.todense()\n",
        "x_0.dot(w)\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "from scipy.special import expit\n",
        "\n",
        "\n",
        "# Cross-entropy\n",
        "\n",
        "def sgd_for_lr_with_ce(X, y, num_passes=5, learning_rate = 0.1):\n",
        "\n",
        "    num_data_points = X.shape[0]\n",
        "\n",
        "    # Initialize theta -> 0\n",
        "    num_features = X.shape[1]\n",
        "    w = np.zeros(num_features)\n",
        "    b = 0.0\n",
        "\n",
        "    # repeat until done\n",
        "    # how to define \"done\"? let's just make it num passes for now\n",
        "    # we can also do norm of gradient and when it is < epsilon (something tiny)\n",
        "    # we stop\n",
        "\n",
        "    for current_pass in range(num_passes):\n",
        "        \n",
        "        # iterate through entire dataset in random order\n",
        "        order = list(range(num_data_points))\n",
        "        random.shuffle(order)\n",
        "        for i in order:\n",
        "\n",
        "            # compute y-hat for this value of i given y_i and x_i\n",
        "            x_i = X[i]\n",
        "            y_i = y[i]\n",
        "\n",
        "            # need to compute based on w and b\n",
        "            # sigmoid(w dot x + b)\n",
        "            z = x_i.dot(w) + b\n",
        "            y_hat_i = expit(z)\n",
        "\n",
        "            # for each w (and b), modify by -lr * (y_hat_i - y_i) * x_i\n",
        "            w = w - learning_rate * (y_hat_i - y_i) * x_i\n",
        "            b = b - learning_rate * (y_hat_i - y_i)\n",
        "\n",
        "    # return theta\n",
        "    return w,b\n",
        "\n",
        "w,b = sgd_for_lr_with_ce(X,y)\n",
        "\n",
        "#w\n",
        "\n",
        "sorted_vocab = sorted([(k,v) for k,v in vectorizer.vocabulary_.items()],key=lambda x:x[1])\n",
        "sorted_vocab = [a for (a,b) in sorted_vocab]\n",
        "\n",
        "sorted_words_weights = sorted([x for x in zip(sorted_vocab, w)], key=lambda x:x[1])\n",
        "sorted_words_weights[-50:]\n",
        "\n",
        "# get the predictions\n",
        "def predict_y_lr(w,b,X,threshold=0.5):\n",
        "\n",
        "    # use our matrix operation version of the logistic regression model\n",
        "    # X dot w + b\n",
        "    # need to make w a column vector so the dimensions line up correctly\n",
        "    y_hat = X.dot( w.reshape((-1,1)) ) + b\n",
        "\n",
        "    # then just check if it's > threshold\n",
        "    preds = np.where(y_hat > threshold,1,0)\n",
        "\n",
        "    return preds\n",
        "\n",
        "preds = predict_y_lr(w,b,X)\n",
        "\n",
        "preds\n",
        "\n",
        "# compute training set results\n",
        "from sklearn.metrics import classification_report\n",
        "w,b = sgd_for_lr_with_ce(X, y, num_passes=10)\n",
        "y_pred = predict_y_lr(w,b,X)\n",
        "print(classification_report(y, y_pred))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMMwD2lPZLls",
        "outputId": "56fe49c6-da68-438b-da67-ca7ceee3ea79"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-17 23:02:09--  https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n",
            "Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 84125825 (80M) [application/x-gzip]\n",
            "Saving to: ‘aclImdb_v1.tar.gz.3’\n",
            "\n",
            "aclImdb_v1.tar.gz.3 100%[===================>]  80.23M  19.9MB/s    in 6.6s    \n",
            "\n",
            "2023-03-17 23:02:15 (12.2 MB/s) - ‘aclImdb_v1.tar.gz.3’ saved [84125825/84125825]\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.99      0.95      1000\n",
            "           1       0.99      0.90      0.94      1000\n",
            "\n",
            "    accuracy                           0.95      2000\n",
            "   macro avg       0.95      0.95      0.95      2000\n",
            "weighted avg       0.95      0.95      0.95      2000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##! wget https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "##! tar -xzf aclImdb_v1.tar.gz\n",
        "\n",
        "from sklearn.datasets import load_files\n",
        "\n",
        "# Load the data\n",
        "train_data = load_files('aclImdb/train/', categories=['pos', 'neg'], shuffle=True, random_state=42)\n",
        "test_data = load_files('aclImdb/test/', categories=['pos', 'neg'], shuffle=True, random_state=42)\n",
        "\n",
        "# Extract the text and labels from the data\n",
        "X_train, y_train = train_data.data, train_data.target\n",
        "X_test, y_test = test_data.data, test_data.target\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Convert the text data into bag-of-words features\n",
        "vectorizer = CountVectorizer()\n",
        "X_train = vectorizer.fit_transform(X_train)\n",
        "X_test = vectorizer.transform(X_test)\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "# Train the logistic regression model\n",
        "clf = LogisticRegression(random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model on the testing set\n",
        "y_pred = clf.predict(X_test)\n",
        "'''acc = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "print('Accuracy:', acc)\n",
        "print('F1-score:', f1)'''\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRUJWjRayMIA",
        "outputId": "d1a6797f-3af6-4ced-df21-3c56f3f37f31"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-17 23:04:36--  https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n",
            "Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 84125825 (80M) [application/x-gzip]\n",
            "Saving to: ‘aclImdb_v1.tar.gz.5’\n",
            "\n",
            "aclImdb_v1.tar.gz.5 100%[===================>]  80.23M  20.5MB/s    in 6.0s    \n",
            "\n",
            "2023-03-17 23:04:42 (13.5 MB/s) - ‘aclImdb_v1.tar.gz.5’ saved [84125825/84125825]\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.87      0.87     12500\n",
            "           1       0.87      0.86      0.86     12500\n",
            "\n",
            "    accuracy                           0.86     25000\n",
            "   macro avg       0.86      0.86      0.86     25000\n",
            "weighted avg       0.86      0.86      0.86     25000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eF5cmkVzj1f",
        "outputId": "983f1de9-d3cc-4028-9f76-ce6b756fcedd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.87      0.87     12500\n",
            "           1       0.87      0.86      0.86     12500\n",
            "\n",
            "    accuracy                           0.86     25000\n",
            "   macro avg       0.86      0.86      0.86     25000\n",
            "weighted avg       0.86      0.86      0.86     25000\n",
            "\n"
          ]
        }
      ]
    }
  ]
}